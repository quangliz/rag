{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlqDjiA6Ui58"
      },
      "source": [
        "### Note\n",
        "From this repo, OpenAI compatibility only, Google GenAI is stupid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wan2nf-1UlHV"
      },
      "source": [
        "### Why?\n",
        "Text chunking is an essential step in Retrieval-Augmented Generation (RAG), where large text bodies are divided into meaningful segments to improve retrieval accuracy. Unlike fixed-length chunking, semantic chunking splits text based on the content similarity between sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQXuWrW5UprS"
      },
      "source": [
        "### Breakpoint Methods\n",
        "- **Percentile**: Find the Xth percentile of all similarity differences and split chunks where drop is greater than this value\n",
        "- **Standard Deviation**: Split where similarity drops more than X standard deviations below them\n",
        "- **Interquartile Range(IQR)**: Use the interquartile distance (Q3 - Q1) to determine split points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF-x5g2LUrfh"
      },
      "source": [
        "### 1. Set up env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "clSx9FAEKKUy"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFWHW5GJU0eT"
      },
      "source": [
        "### 2. Extract text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzHXnXvgL0CY",
        "outputId": "47cc777a-841d-43ac-968d-6fc24ad1319d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Understanding Artificial Intelligence \n",
            "Chapter 1: Introduction to Artificial Intelligence \n",
            "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
            "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
            "the project of developing systems endowed with the intellectual processes characteristic of \n",
            "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
            "experience. Over the past f\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extracts text from a PDF file and prints the first `num_chars` characters.\n",
        "\n",
        "    Args:\n",
        "    pdf_path (str): Path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "    str: Extracted text from the PDF.\n",
        "    \"\"\"\n",
        "    # Open the PDF file\n",
        "    mypdf = fitz.open(pdf_path)\n",
        "    all_text = \"\"  # Initialize an empty string to store the extracted text\n",
        "\n",
        "    # Iterate through each page in the PDF\n",
        "    for page in mypdf:\n",
        "        all_text += page.get_text(\"text\") + \" \"\n",
        "\n",
        "    return all_text.strip()  # Return the extracted text\n",
        "# Define the path to the PDF file\n",
        "pdf_path = \"../data/AI_Information.pdf\"\n",
        "\n",
        "# Extract text from the PDF file\n",
        "extracted_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Print the first 500 characters of the extracted text\n",
        "print(extracted_text[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhsOk-qWU3u9"
      },
      "source": [
        "### 3. Create sentence-level embedding\n",
        "\n",
        "We split text into sentences and generate embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I implement embed function using pretrained model because Gemini limits requests per minute.\n",
        "\n",
        "This model runs smoothly on my GTX 1650 with 4 VRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62aOOSZMSazq",
        "outputId": "e683afdd-06f3-4ab4-d1f3-665404da6d72"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModel.from_pretrained(\"BAAI/bge-base-en\").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-base-en\")\n",
        "\n",
        "def embed(text):\n",
        "    if isinstance(text, str): text = [text]\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(**inputs)\n",
        "        embedding = F.normalize(output.last_hidden_state[:, 0, :], p=2, dim=1)\n",
        "    return embedding.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFs2biInMukU",
        "outputId": "9a2fb156-0432-41e6-88ca-47aaa5cdfa9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 257 sentence embeddings.\n"
          ]
        }
      ],
      "source": [
        "# Splitting text into sentences\n",
        "sentences = extracted_text.split(\". \")  # Optional: dùng nltk/sentencepiece cho chính xác hơn\n",
        "\n",
        "# Get all embeddings\n",
        "embeddings = embed(sentences)\n",
        "\n",
        "print(f\"Generated {len(embeddings)} sentence embeddings.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk4fyZEpTxp4",
        "outputId": "7726901a-bc17-4424-832c-5a644ac9ec2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.01306901,  0.04015021, -0.00235185, ..., -0.02536607,\n",
              "         0.00107017, -0.00399907],\n",
              "       [-0.00877151,  0.0327035 ,  0.00057982, ..., -0.02138391,\n",
              "        -0.00518402,  0.00479695],\n",
              "       [-0.01059035,  0.00150866, -0.00066208, ..., -0.01109738,\n",
              "         0.00259597, -0.00476295],\n",
              "       ...,\n",
              "       [ 0.01444942,  0.03102358, -0.00610783, ..., -0.01105188,\n",
              "         0.00620361,  0.00885018],\n",
              "       [ 0.02855043, -0.02881697,  0.0228119 , ..., -0.01229273,\n",
              "         0.02225733,  0.00549865],\n",
              "       [ 0.01170838, -0.00375156, -0.00367259, ..., -0.01511175,\n",
              "        -0.00050225, -0.00193483]], shape=(257, 768), dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UzdwgigVENO"
      },
      "source": [
        "### 4. Calculate similarities\n",
        "We compute cosine similarity between consecutive sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrBctvXWM6Of",
        "outputId": "97782861-7565-40a9-fa35-2a86ca9a7a68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0.78351605]], dtype=float32),\n",
              " array([[0.79600334]], dtype=float32),\n",
              " array([[0.84577465]], dtype=float32),\n",
              " array([[0.8563843]], dtype=float32),\n",
              " array([[0.86224794]], dtype=float32),\n",
              " array([[0.85106635]], dtype=float32),\n",
              " array([[0.80903834]], dtype=float32),\n",
              " array([[0.8385702]], dtype=float32),\n",
              " array([[0.8805547]], dtype=float32),\n",
              " array([[0.9036343]], dtype=float32),\n",
              " array([[0.8707457]], dtype=float32),\n",
              " array([[0.7875351]], dtype=float32),\n",
              " array([[0.7268816]], dtype=float32),\n",
              " array([[0.86637866]], dtype=float32),\n",
              " array([[0.8530915]], dtype=float32),\n",
              " array([[0.89408314]], dtype=float32),\n",
              " array([[0.8129629]], dtype=float32),\n",
              " array([[0.80566347]], dtype=float32),\n",
              " array([[0.8363713]], dtype=float32),\n",
              " array([[0.76574343]], dtype=float32),\n",
              " array([[0.8858226]], dtype=float32),\n",
              " array([[0.8135253]], dtype=float32),\n",
              " array([[0.77825916]], dtype=float32),\n",
              " array([[0.8125247]], dtype=float32),\n",
              " array([[0.81830573]], dtype=float32),\n",
              " array([[0.87223226]], dtype=float32),\n",
              " array([[0.882202]], dtype=float32),\n",
              " array([[0.8855544]], dtype=float32),\n",
              " array([[0.82939184]], dtype=float32),\n",
              " array([[0.8456166]], dtype=float32),\n",
              " array([[0.8047324]], dtype=float32),\n",
              " array([[0.8848734]], dtype=float32),\n",
              " array([[0.8128583]], dtype=float32),\n",
              " array([[0.8548317]], dtype=float32),\n",
              " array([[0.8748833]], dtype=float32),\n",
              " array([[0.81174386]], dtype=float32),\n",
              " array([[0.87621427]], dtype=float32),\n",
              " array([[0.895276]], dtype=float32),\n",
              " array([[0.8238986]], dtype=float32),\n",
              " array([[0.8934659]], dtype=float32),\n",
              " array([[0.8148811]], dtype=float32),\n",
              " array([[0.9021753]], dtype=float32),\n",
              " array([[0.8284098]], dtype=float32),\n",
              " array([[0.91623336]], dtype=float32),\n",
              " array([[0.83801365]], dtype=float32),\n",
              " array([[0.87652373]], dtype=float32),\n",
              " array([[0.8362967]], dtype=float32),\n",
              " array([[0.91067624]], dtype=float32),\n",
              " array([[0.8339933]], dtype=float32),\n",
              " array([[0.8970351]], dtype=float32),\n",
              " array([[0.77405536]], dtype=float32),\n",
              " array([[0.90513945]], dtype=float32),\n",
              " array([[0.8426794]], dtype=float32),\n",
              " array([[0.85654765]], dtype=float32),\n",
              " array([[0.92328876]], dtype=float32),\n",
              " array([[0.8668348]], dtype=float32),\n",
              " array([[0.8629229]], dtype=float32),\n",
              " array([[0.827278]], dtype=float32),\n",
              " array([[0.86852765]], dtype=float32),\n",
              " array([[0.7740247]], dtype=float32),\n",
              " array([[0.874965]], dtype=float32),\n",
              " array([[0.8818078]], dtype=float32),\n",
              " array([[0.8581615]], dtype=float32),\n",
              " array([[0.8689672]], dtype=float32),\n",
              " array([[0.9144722]], dtype=float32),\n",
              " array([[0.8107263]], dtype=float32),\n",
              " array([[0.8579577]], dtype=float32),\n",
              " array([[0.8770268]], dtype=float32),\n",
              " array([[0.8320688]], dtype=float32),\n",
              " array([[0.87534046]], dtype=float32),\n",
              " array([[0.826358]], dtype=float32),\n",
              " array([[0.92484015]], dtype=float32),\n",
              " array([[0.8823449]], dtype=float32),\n",
              " array([[0.8830713]], dtype=float32),\n",
              " array([[0.83245385]], dtype=float32),\n",
              " array([[0.92446566]], dtype=float32),\n",
              " array([[0.83364874]], dtype=float32),\n",
              " array([[0.78921336]], dtype=float32),\n",
              " array([[0.7896045]], dtype=float32),\n",
              " array([[0.78869677]], dtype=float32),\n",
              " array([[0.89016503]], dtype=float32),\n",
              " array([[0.8261647]], dtype=float32),\n",
              " array([[0.8658658]], dtype=float32),\n",
              " array([[0.88199234]], dtype=float32),\n",
              " array([[0.8699449]], dtype=float32),\n",
              " array([[0.79149747]], dtype=float32),\n",
              " array([[0.8317106]], dtype=float32),\n",
              " array([[0.8669169]], dtype=float32),\n",
              " array([[0.85015786]], dtype=float32),\n",
              " array([[0.9139421]], dtype=float32),\n",
              " array([[0.7955773]], dtype=float32),\n",
              " array([[0.8273576]], dtype=float32),\n",
              " array([[0.8158655]], dtype=float32),\n",
              " array([[0.863067]], dtype=float32),\n",
              " array([[0.8668169]], dtype=float32),\n",
              " array([[0.8702019]], dtype=float32),\n",
              " array([[0.84741926]], dtype=float32),\n",
              " array([[0.86209536]], dtype=float32),\n",
              " array([[0.85118055]], dtype=float32),\n",
              " array([[0.88542503]], dtype=float32),\n",
              " array([[0.78825283]], dtype=float32),\n",
              " array([[0.86003256]], dtype=float32),\n",
              " array([[0.8743166]], dtype=float32),\n",
              " array([[0.9030085]], dtype=float32),\n",
              " array([[0.8353929]], dtype=float32),\n",
              " array([[0.93250823]], dtype=float32),\n",
              " array([[0.8215194]], dtype=float32),\n",
              " array([[0.90455425]], dtype=float32),\n",
              " array([[0.8779015]], dtype=float32),\n",
              " array([[0.91856647]], dtype=float32),\n",
              " array([[0.8308084]], dtype=float32),\n",
              " array([[0.8985138]], dtype=float32),\n",
              " array([[0.8062813]], dtype=float32),\n",
              " array([[0.8775887]], dtype=float32),\n",
              " array([[0.8562213]], dtype=float32),\n",
              " array([[0.8593537]], dtype=float32),\n",
              " array([[0.86302567]], dtype=float32),\n",
              " array([[0.8998592]], dtype=float32),\n",
              " array([[0.8258083]], dtype=float32),\n",
              " array([[0.8263931]], dtype=float32),\n",
              " array([[0.7987404]], dtype=float32),\n",
              " array([[0.88368815]], dtype=float32),\n",
              " array([[0.80030125]], dtype=float32),\n",
              " array([[0.9133817]], dtype=float32),\n",
              " array([[0.90517473]], dtype=float32),\n",
              " array([[0.88774157]], dtype=float32),\n",
              " array([[0.8316329]], dtype=float32),\n",
              " array([[0.9233765]], dtype=float32),\n",
              " array([[0.8665443]], dtype=float32),\n",
              " array([[0.9398555]], dtype=float32),\n",
              " array([[0.8963318]], dtype=float32),\n",
              " array([[0.9033488]], dtype=float32),\n",
              " array([[0.83461815]], dtype=float32),\n",
              " array([[0.8919647]], dtype=float32),\n",
              " array([[0.8750818]], dtype=float32),\n",
              " array([[0.8836306]], dtype=float32),\n",
              " array([[0.794148]], dtype=float32),\n",
              " array([[0.80853534]], dtype=float32),\n",
              " array([[0.8370753]], dtype=float32),\n",
              " array([[0.92031455]], dtype=float32),\n",
              " array([[0.85223484]], dtype=float32),\n",
              " array([[0.8261008]], dtype=float32),\n",
              " array([[0.7521422]], dtype=float32),\n",
              " array([[0.88623154]], dtype=float32),\n",
              " array([[0.8555545]], dtype=float32),\n",
              " array([[0.8915486]], dtype=float32),\n",
              " array([[0.8972744]], dtype=float32),\n",
              " array([[0.9220067]], dtype=float32),\n",
              " array([[0.80287164]], dtype=float32),\n",
              " array([[0.8659905]], dtype=float32),\n",
              " array([[0.8413885]], dtype=float32),\n",
              " array([[0.921541]], dtype=float32),\n",
              " array([[0.81551665]], dtype=float32),\n",
              " array([[0.9121876]], dtype=float32),\n",
              " array([[0.90789306]], dtype=float32),\n",
              " array([[0.8495452]], dtype=float32),\n",
              " array([[0.7886127]], dtype=float32),\n",
              " array([[0.92291135]], dtype=float32),\n",
              " array([[0.85717905]], dtype=float32),\n",
              " array([[0.9263085]], dtype=float32),\n",
              " array([[0.8834429]], dtype=float32),\n",
              " array([[0.8973334]], dtype=float32),\n",
              " array([[0.8226859]], dtype=float32),\n",
              " array([[0.8500418]], dtype=float32),\n",
              " array([[0.9064679]], dtype=float32),\n",
              " array([[0.885758]], dtype=float32),\n",
              " array([[0.85629785]], dtype=float32),\n",
              " array([[0.88223493]], dtype=float32),\n",
              " array([[0.8490796]], dtype=float32),\n",
              " array([[0.9254701]], dtype=float32),\n",
              " array([[0.8881507]], dtype=float32),\n",
              " array([[0.89675885]], dtype=float32),\n",
              " array([[0.81128216]], dtype=float32),\n",
              " array([[0.9045905]], dtype=float32),\n",
              " array([[0.9131537]], dtype=float32),\n",
              " array([[0.8699844]], dtype=float32),\n",
              " array([[0.8165976]], dtype=float32),\n",
              " array([[0.9070675]], dtype=float32),\n",
              " array([[0.8606541]], dtype=float32),\n",
              " array([[0.92265844]], dtype=float32),\n",
              " array([[0.8579072]], dtype=float32),\n",
              " array([[0.9018853]], dtype=float32),\n",
              " array([[0.74521935]], dtype=float32),\n",
              " array([[0.8788174]], dtype=float32),\n",
              " array([[0.8260577]], dtype=float32),\n",
              " array([[0.9091923]], dtype=float32),\n",
              " array([[0.8445773]], dtype=float32),\n",
              " array([[0.92587817]], dtype=float32),\n",
              " array([[0.83528143]], dtype=float32),\n",
              " array([[0.8835015]], dtype=float32),\n",
              " array([[0.83554476]], dtype=float32),\n",
              " array([[0.8673891]], dtype=float32),\n",
              " array([[0.783432]], dtype=float32),\n",
              " array([[0.8668785]], dtype=float32),\n",
              " array([[0.90462667]], dtype=float32),\n",
              " array([[0.893283]], dtype=float32),\n",
              " array([[0.85851353]], dtype=float32),\n",
              " array([[0.9180742]], dtype=float32),\n",
              " array([[0.8486106]], dtype=float32),\n",
              " array([[0.8978394]], dtype=float32),\n",
              " array([[0.83801544]], dtype=float32),\n",
              " array([[0.87046015]], dtype=float32),\n",
              " array([[0.79233205]], dtype=float32),\n",
              " array([[0.9047439]], dtype=float32),\n",
              " array([[0.90270853]], dtype=float32),\n",
              " array([[0.94041634]], dtype=float32),\n",
              " array([[0.869362]], dtype=float32),\n",
              " array([[0.92338836]], dtype=float32),\n",
              " array([[0.90043485]], dtype=float32),\n",
              " array([[0.9018853]], dtype=float32),\n",
              " array([[0.8011551]], dtype=float32),\n",
              " array([[0.9099517]], dtype=float32),\n",
              " array([[0.8229352]], dtype=float32),\n",
              " array([[0.8487077]], dtype=float32),\n",
              " array([[0.850171]], dtype=float32),\n",
              " array([[0.82095414]], dtype=float32),\n",
              " array([[0.8518469]], dtype=float32),\n",
              " array([[0.82487595]], dtype=float32),\n",
              " array([[0.9358871]], dtype=float32),\n",
              " array([[0.86660856]], dtype=float32),\n",
              " array([[0.80692315]], dtype=float32),\n",
              " array([[0.89560497]], dtype=float32),\n",
              " array([[0.8663207]], dtype=float32),\n",
              " array([[0.9003379]], dtype=float32),\n",
              " array([[0.813789]], dtype=float32),\n",
              " array([[0.8275861]], dtype=float32),\n",
              " array([[0.7455748]], dtype=float32),\n",
              " array([[0.8943478]], dtype=float32),\n",
              " array([[0.8306353]], dtype=float32),\n",
              " array([[0.9106131]], dtype=float32),\n",
              " array([[0.83084595]], dtype=float32),\n",
              " array([[0.8706406]], dtype=float32),\n",
              " array([[0.8359581]], dtype=float32),\n",
              " array([[0.86546093]], dtype=float32),\n",
              " array([[0.8285297]], dtype=float32),\n",
              " array([[0.91289544]], dtype=float32),\n",
              " array([[0.9022103]], dtype=float32),\n",
              " array([[0.8714994]], dtype=float32),\n",
              " array([[0.8449765]], dtype=float32),\n",
              " array([[0.8537708]], dtype=float32),\n",
              " array([[0.8392022]], dtype=float32),\n",
              " array([[0.820747]], dtype=float32),\n",
              " array([[0.80568635]], dtype=float32),\n",
              " array([[0.87289566]], dtype=float32),\n",
              " array([[0.7635045]], dtype=float32),\n",
              " array([[0.87821805]], dtype=float32),\n",
              " array([[0.823394]], dtype=float32),\n",
              " array([[0.7838845]], dtype=float32),\n",
              " array([[0.7617589]], dtype=float32),\n",
              " array([[0.8914664]], dtype=float32),\n",
              " array([[0.8473274]], dtype=float32),\n",
              " array([[0.79802835]], dtype=float32),\n",
              " array([[0.762289]], dtype=float32),\n",
              " array([[0.88400483]], dtype=float32),\n",
              " array([[0.8682297]], dtype=float32),\n",
              " array([[0.86219907]], dtype=float32)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similarities = [cosine_similarity(embeddings[i].reshape(1, -1), embeddings[i + 1].reshape(1, -1)) for i in range(len(embeddings) - 1)]\n",
        "similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDa4jpXUVPuL"
      },
      "source": [
        "### 5. Implementing Semantic Chunking\n",
        "implement three different methods for finding breakpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q08uQbvKM9KZ",
        "outputId": "38265e73-b38f-4b93-bb35-6eca75a90b6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 128,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 152,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 158,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 206,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def compute_breakpoints(similarities, method=\"percentile\", threshold=90):\n",
        "    \"\"\"\n",
        "    Computes chunking breakpoints based on similarity drops.\n",
        "\n",
        "    Args:\n",
        "    similarities (List[float]): List of similarity scores between sentences.\n",
        "    method (str): 'percentile', 'standard_deviation', or 'interquartile'.\n",
        "    threshold (float): Threshold value (percentile for 'percentile', std devs for 'standard_deviation').\n",
        "\n",
        "    Returns:\n",
        "    List[int]: Indices where chunk splits should occur.\n",
        "    \"\"\"\n",
        "    # Determine the threshold value based on the selected method\n",
        "    if method == \"percentile\":\n",
        "        # Calculate the Xth percentile of the similarity scores\n",
        "        threshold_value = np.percentile(similarities, threshold)\n",
        "    elif method == \"standard_deviation\":\n",
        "        # Calculate the mean and standard deviation of the similarity scores\n",
        "        mean = np.mean(similarities)\n",
        "        std_dev = np.std(similarities)\n",
        "        # Set the threshold value to mean minus X standard deviations\n",
        "        threshold_value = mean - (threshold * std_dev)\n",
        "    elif method == \"interquartile\":\n",
        "        # Calculate the first and third quartiles (Q1 and Q3)\n",
        "        q1, q3 = np.percentile(similarities, [25, 75])\n",
        "        # Set the threshold value using the IQR rule for outliers\n",
        "        threshold_value = q1 - 1.5 * (q3 - q1)\n",
        "    else:\n",
        "        # Raise an error if an invalid method is provided\n",
        "        raise ValueError(\"Invalid method. Choose 'percentile', 'standard_deviation', or 'interquartile'.\")\n",
        "\n",
        "    # Identify indices where similarity drops below the threshold value\n",
        "    return [i for i, sim in enumerate(similarities) if sim < threshold_value]\n",
        "\n",
        "# Compute breakpoints using the percentile method with a threshold of 90\n",
        "breakpoints = compute_breakpoints(similarities, method=\"percentile\", threshold=90)\n",
        "breakpoints\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2slC7mLVWDg"
      },
      "source": [
        "### 6. Splitting Text into Semantic Chunks\n",
        "\n",
        "We split the text based on computed breakpoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeW2AaIWNBdE",
        "outputId": "349fdc0c-c446-413c-ffab-225c5c714a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of semantic chunks: 231\n",
            "\n",
            "First text chunk:\n",
            "['Understanding Artificial Intelligence \\nChapter 1: Introduction to Artificial Intelligence \\nArtificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \\nto perform tasks commonly associated with intelligent beings.', 'The term is frequently applied to \\nthe project of developing systems endowed with the intellectual processes characteristic of \\nhumans, such as the ability to reason, discover meaning, generalize, or learn from past \\nexperience.', 'Over the past few decades, advancements in computing power and data availability \\nhave significantly accelerated the development and deployment of AI.', '\\nHistorical Context \\nThe idea of artificial intelligence has existed for centuries, often depicted in myths and fiction.', '\\nHowever, the formal field of AI research began in the mid-20th century.', 'The Dartmouth Workshop \\nin 1956 is widely considered the birthplace of AI.', 'Early AI research focused on problem-solving \\nand symbolic methods.', 'The 1980s saw a rise in expert systems, while the 1990s and 2000s \\nbrought advancements in machine learning and neural networks.', 'Recent breakthroughs in deep \\nlearning have revolutionized the field.', '\\nModern Observations \\nModern AI systems are increasingly prevalent in everyday life.', 'From virtual assistants like Siri and \\nAlexa to recommendation algorithms on streaming services and social media, AI is impacting \\nhow we live, work, and interact.', 'The development of self-driving cars, advanced medical \\ndiagnostics, and sophisticated financial modeling tools demonstrates the broad and growing \\napplications of AI.', 'Concerns about ethical implications, bias, and job displacement are also \\nincreasingly prominent.', '\\nChapter 2: Core Concepts of Artificial Intelligence \\nMachine Learning \\nMachine learning (ML) is a subset of AI that focuses on enabling systems to learn from data \\nwithout being explicitly programmed.', 'ML algorithms identify patterns, make predictions, and \\nimprove their performance over time as they are exposed to more data.', '\\nSupervised Learning \\nIn supervised learning, algorithms are trained on labeled data, where the input data is paired with \\nthe correct output.', 'This allows the algorithm to learn the relationship between inputs and outputs \\nand make predictions on new, unseen data.', 'Examples include image classification and spam \\ndetection.', '\\nUnsupervised Learning \\nUnsupervised learning algorithms are trained on unlabeled data, where the algorithm must \\ndiscover patterns and structures in the data without explicit guidance.', 'Common techniques \\ninclude clustering (grouping similar data points) and dimensionality reduction (reducing the \\nnumber of variables while preserving important information).', '\\n \\n Reinforcement Learning \\nReinforcement learning involves training an agent to make decisions in an environment to \\nmaximize a reward.', 'The agent learns through trial and error, receiving feedback in the form of \\nrewards or penalties.', 'This approach is used in game playing, robotics, and resource \\nmanagement.', '\\nDeep Learning \\nDeep learning is a subfield of machine learning that uses artificial neural networks with multiple \\nlayers (deep neural networks) to analyze data.', 'These networks are inspired by the structure and \\nfunction of the human brain.', 'Deep learning has achieved significant breakthroughs in areas such \\nas image recognition, natural language processing, and speech recognition.', '\\nConvolutional Neural Networks (CNNs) \\nCNNs are a type of deep neural network particularly effective for processing images and videos.', '\\nThey use convolutional layers to automatically learn features from the input data.', 'CNNs are \\nwidely used in object detection, facial recognition, and medical image analysis.', '\\nRecurrent Neural Networks (RNNs) \\nRNNs are designed to process sequential data, such as text and time series.', 'They have feedback \\nconnections that allow information to persist over time, making them suitable for tasks like \\nlanguage translation, speech recognition, and sentiment analysis.', '\\nNatural Language Processing (NLP) \\nNatural Language Processing (NLP) is a branch of AI that focuses on enabling computers to \\nunderstand, interpret, and generate human language.', 'NLP techniques are used in chatbots, \\nmachine translation, text summarization, and sentiment analysis.', '\\nComputer Vision \\nComputer vision is a field of AI that enables computers to \"see\" and interpret images and videos.', '\\nThis involves tasks such as object detection, image segmentation, and facial recognition.', '\\nComputer vision is used in self-driving cars, medical imaging, and surveillance systems.', '\\nChapter 3: Applications of Artificial Intelligence \\nThe applications of AI are vast and continue to expand across various industries and domains.', '\\nThese applications include: \\nHealthcare \\nAI is transforming healthcare through applications such as medical diagnosis, drug discovery, \\npersonalized medicine, and robotic surgery.', 'AI-powered tools can analyze medical images, \\npredict patient outcomes, and assist in treatment planning.', '\\nFinance \\nIn finance, AI is used for fraud detection, algorithmic trading, risk management, and customer \\nservice.', 'AI algorithms can analyze large datasets to identify patterns, predict market trends, and \\nautomate financial processes.', '\\n  \\nTransportation \\nAI is revolutionizing transportation with the development of self-driving cars, traffic optimization \\nsystems, and logistics management.', 'Autonomous vehicles use AI to perceive their surroundings, \\nmake driving decisions, and navigate safely.', '\\nRetail \\nThe retail industry uses AI for personalized recommendations, inventory management, customer \\nservice chatbots, and supply chain optimization. AI-powered systems can analyze customer data \\nto predict demand, personalize offers, and improve the shopping experience.', '\\nManufacturing \\nAI is used in manufacturing for predictive maintenance, quality control, process optimization, \\nand robotics.', 'AI-powered systems can monitor equipment, detect anomalies, and automate \\ntasks, leading to increased efficiency and reduced costs.', '\\nEducation \\nAI is enhancing education through personalized learning platforms, automated grading systems, \\nand virtual tutors.', 'AI-powered tools can adapt to individual student needs, provide feedback, and \\ncreate customized learning experiences.', '\\nEntertainment \\nThe entertainment industry uses AI for content recommendation, game development, and virtual \\nreality experiences.', 'AI algorithms analyze user preferences to suggest movies, music, and \\ngames, enhancing user engagement.', '\\nCybersecurity \\nAI is used in cybersecurity to detect and respond to threats, analyze network traffic, and identify \\nvulnerabilities.', 'AI-powered systems can automate security tasks, improve threat detection \\naccuracy, and enhance overall cybersecurity posture.', '\\nChapter 4: Ethical and Societal Implications of AI \\nThe rapid development and deployment of AI raise significant ethical and societal concerns.', '\\nThese concerns include: \\nBias and Fairness \\nAI systems can inherit and amplify biases present in the data they are trained on, leading to unfair \\nor discriminatory outcomes. Ensuring fairness and mitigating bias in AI systems is a critical \\nchallenge.', '\\nTransparency and Explainability \\nMany AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to \\nunderstand how they arrive at their decisions.', 'Enhancing transparency and explainability is \\ncrucial for building trust and accountability.', '\\n \\n  \\nPrivacy and Security \\nAI systems often rely on large amounts of data, raising concerns about privacy and data security.', '\\nProtecting sensitive information and ensuring responsible data handling are essential.', '\\nJob Displacement \\nThe automation capabilities of AI have raised concerns about job displacement, particularly in \\nindustries with repetitive or routine tasks.', 'Addressing the potential economic and social impacts \\nof AI-driven automation is a key challenge.', '\\nAutonomy and Control \\nAs AI systems become more autonomous, questions arise about control, accountability, and the \\npotential for unintended consequences.', 'Establishing clear guidelines and ethical frameworks for \\nAI development and deployment is crucial.', '\\nWeaponization of AI \\nThe potential use of AI in autonomous weapons systems raises significant ethical and security \\nconcerns. International discussions and regulations are needed to address the risks associated \\nwith AI-powered weapons.', '\\nChapter 5: The Future of Artificial Intelligence \\nThe future of AI is likely to be characterized by continued advancements and broader adoption \\nacross various domains.', 'Key trends and areas of development include: \\nExplainable AI (XAI) \\nExplainable AI (XAI) aims to make AI systems more transparent and understandable.', 'XAI \\ntechniques are being developed to provide insights into how AI models make decisions, \\nenhancing trust and accountability.', '\\nAI at the Edge \\nAI at the edge involves processing data locally on devices, rather than relying on cloud-based \\nservers.', 'This approach reduces latency, improves privacy, and enables AI applications in \\nenvironments with limited connectivity.', '\\nQuantum Computing and AI \\nQuantum computing has the potential to significantly accelerate AI algorithms, enabling \\nbreakthroughs in areas such as drug discovery, materials science, and optimization. The \\nintersection of quantum computing and AI is a promising area of research.', '\\nHuman-AI Collaboration \\nThe future of AI is likely to involve increased collaboration between humans and AI systems.', 'This \\nincludes developing AI tools that augment human capabilities, support decision-making, and \\nenhance productivity.', '\\n \\n  \\n \\nAI for Social Good \\nAI is increasingly being used to address social and environmental challenges, such as climate \\nchange, poverty, and healthcare disparities. AI for social good initiatives aim to leverage AI for \\npositive impact.', '\\nRegulation and Governance \\nAs AI becomes more pervasive, there will be a growing need for regulation and governance to \\nensure responsible development and deployment.', 'This includes establishing ethical guidelines, \\naddressing \\nbias \\nand \\nfairness, \\nand \\nprotecting \\nprivacy \\nand \\nsecurity.', '\\nInternational collaborations on standards will be important.', '\\nBy understanding the core concepts, applications, ethical implications, and future directions of \\nAI, we can better navigate the opportunities and challenges presented by this transformative \\ntechnology.', 'Continued research, responsible development, and thoughtful governance are \\nessential for realizing the full potential of AI while mitigating its risks.', '\\nChapter 6: AI and Robotics \\nIntegration of AI and Robotics \\nThe integration of AI and robotics combines the physical capabilities of robots with the cognitive \\nabilities of AI.', 'This synergy enables robots to perform complex tasks, adapt to changing \\nenvironments, and interact with humans more naturally.', 'AI-powered robots are used in \\nmanufacturing, healthcare, logistics, and exploration.', '\\nTypes of Robots \\nIndustrial Robots \\nIndustrial robots are used in manufacturing for tasks such as welding, painting, assembly, and \\nmaterial handling.', 'AI enhances their precision, efficiency, and adaptability, allowing them to work \\nalongside humans in collaborative settings (cobots).', '\\nService Robots \\nService robots assist humans in various tasks, including cleaning, delivery, customer service, and \\nhealthcare.', 'AI enables these robots to navigate, interact with people, and perform tasks \\nautonomously or semi-autonomously.', '\\nSurgical Robots \\nSurgical robots assist surgeons in performing complex procedures with greater precision and \\ncontrol. AI-powered surgical robots can enhance dexterity, reduce invasiveness, and improve \\npatient outcomes.', '\\nExploration Robots \\n Exploration robots are designed to operate in hazardous or inaccessible environments, such as \\nspace, deep sea, and disaster zones.', 'AI enables these robots to navigate, collect data, and make \\ndecisions autonomously.', '\\n \\n \\nRobot Learning \\nImitation Learning \\nImitation learning involves training robots to perform tasks by observing human demonstrations.', '\\nThis approach allows robots to learn complex behaviors without explicit programming.', '\\nReinforcement Learning for Robots \\nReinforcement learning is used to train robots to perform tasks through trial and error, receiving \\nrewards for successful actions.', 'This approach enables robots to adapt to changing environments \\nand optimize their performance over time.', '\\nRobot Navigation and Perception \\nSLAM (Simultaneous Localization and Mapping) \\nSLAM technology enables robots to build a map of an unknown environment while \\nsimultaneously keeping track of their location within that map.', 'This is crucial for autonomous \\nnavigation in dynamic environments.', '\\nComputer Vision for Robots \\nComputer vision provides robots with the ability to \"see\" and interpret their surroundings.', 'This \\nincludes object recognition, scene understanding, and obstacle avoidance.', '\\nChapter 7: AI in Business and Industry \\nTransforming Business Operations \\nAI is transforming business operations across various industries, leading to increased efficiency, \\nreduced costs, and improved decision-making.', 'AI-powered tools automate tasks, analyze data, \\nand provide insights that drive business growth.', '\\nCustomer Relationship Management (CRM) \\nAI enhances CRM systems by providing personalized customer experiences, predicting customer \\nbehavior, and automating customer service interactions.', 'AI-powered chatbots, recommendation \\nengines, and sentiment analysis tools improve customer engagement and satisfaction.', '\\nSupply Chain Management \\nAI optimizes supply chain operations by predicting demand, managing inventory, and \\nstreamlining logistics. AI-powered systems improve forecasting accuracy, reduce waste, and \\nenhance supply chain resilience.', '\\nHuman Resources (HR) \\n AI is used in HR for talent acquisition, employee onboarding, performance management, and \\ntraining.', 'AI-powered tools automate recruitment processes, personalize training programs, and \\nprovide insights into employee engagement and retention.', '\\nMarketing and Sales \\nAI enhances marketing and sales efforts by analyzing customer data, personalizing marketing \\ncampaigns, and predicting sales trends. AI-powered tools improve targeting, optimize ad \\nspending, and enhance customer segmentation.', '\\nFinancial Services \\nAI is used in financial services for fraud detection, risk management, algorithmic trading, and \\ncustomer service.', 'AI-powered systems analyze large datasets to identify patterns, predict market \\nmovements, and automate financial processes.', '\\nChapter 8: AI and the Future of Work \\nAutomation and Job Displacement \\nThe increasing capabilities of AI raise concerns about job displacement, particularly in industries \\nwith repetitive or routine tasks.', 'While AI may automate some jobs, it also creates new \\nopportunities and transforms existing roles.', '\\nReskilling and Upskilling \\nAddressing the potential impacts of AI on the workforce requires reskilling and upskilling \\ninitiatives.', 'These programs equip workers with the skills needed to adapt to new roles and \\ncollaborate with AI systems.', '\\nHuman-AI Collaboration \\nThe future of work is likely to involve increased collaboration between humans and AI systems.', 'AI \\ntools can augment human capabilities, automate mundane tasks, and provide insights that \\nsupport decision-making.', '\\nNew Job Roles \\nThe development and deployment of AI create new job roles in areas such as AI development, \\ndata science, AI ethics, and AI training.', 'These roles require specialized skills and expertise.', '\\nEthical Considerations \\nAddressing the ethical implications of AI in the workplace is crucial.', 'This includes ensuring \\nfairness, transparency, and accountability in AI systems, as well as protecting worker rights and \\nprivacy.', '\\nChapter 9: AI, Creativity, and Innovation \\nAI as a Creative Tool \\nAI is increasingly being used as a tool for creativity and innovation. AI-powered systems can \\ngenerate art, music, and literature, assist in design processes, and accelerate scientific \\ndiscovery.', '\\n AI-Generated Art \\nAI algorithms can create original works of art, including paintings, drawings, and sculptures.', '\\nThese systems learn from existing art and generate new pieces that exhibit unique styles and \\npatterns.', '\\nAI in Music Composition \\nAI is used to compose music, generate melodies, and create arrangements. AI-powered tools can \\nassist musicians in the creative process, offering new possibilities for musical expression.', '\\nAI in Writing and Content Creation \\nAI is used to write articles, generate content, and create scripts. AI-powered writing tools can \\nassist writers with research, editing, and content generation, enhancing productivity and \\ncreativity.', '\\nAI-Driven Innovation \\nAI accelerates innovation by analyzing large datasets, identifying patterns, and generating new \\nideas.', 'AI-powered tools are used in research and development, product design, and problem-\\nsolving across various industries.', '\\nChapter 10: AI and Education \\nPersonalized Learning \\nAI enables personalized learning experiences by adapting to individual student needs and \\nlearning styles.', 'AI-powered platforms provide customized content, feedback, and pacing, \\nenhancing student engagement and outcomes.', '\\nAdaptive Assessments \\nAI-powered assessments adjust the difficulty of questions based on student performance, \\nproviding a more accurate measure of knowledge and skills.', 'Adaptive assessments can also \\nidentify learning gaps and inform instructional strategies.', '\\nVirtual Tutors and Learning Assistants \\nAI-powered virtual tutors and learning assistants provide personalized support to students, \\nanswering questions, offering guidance, and tracking progress.', 'These tools enhance access to \\neducation and improve learning outcomes.', '\\nAutomated Grading and Feedback \\nAI automates grading and feedback processes, saving educators time and providing timely \\nfeedback to students. AI-powered systems can assess essays, assignments, and exams, \\nidentifying areas for improvement.', '\\nEducational Data Mining \\nEducational data mining uses AI to analyze student data, identify patterns, and predict learning \\noutcomes.', 'This information can inform instructional strategies, improve educational programs, \\nand enhance student support services.', '\\n \\n Chapter 11: AI and Healthcare \\nMedical Diagnosis and Treatment \\nAI is revolutionizing medical diagnosis and treatment by analyzing medical images, predicting \\npatient outcomes, and assisting in treatment planning.', 'AI-powered tools enhance accuracy, \\nefficiency, and patient care.', '\\nDrug Discovery and Development \\nAI accelerates drug discovery and development by analyzing biological data, predicting drug \\nefficacy, and identifying potential drug candidates.', 'AI-powered systems reduce the time and cost \\nof bringing new treatments to market.', '\\nPersonalized Medicine \\nAI enables personalized medicine by analyzing individual patient data, predicting treatment \\nresponses, and tailoring interventions. Personalized medicine enhances treatment effectiveness \\nand reduces adverse effects.', '\\nRobotic Surgery \\nAI-powered robotic surgery systems assist surgeons in performing complex procedures with \\ngreater precision and control.', 'These systems enhance dexterity, reduce invasiveness, and \\nimprove patient outcomes.', '\\nHealthcare Administration \\nAI streamlines healthcare administration by automating tasks, managing patient records, and \\noptimizing workflows. AI-powered systems improve efficiency, reduce costs, and enhance \\npatient experience.', '\\nChapter 12: AI and Cybersecurity \\nThreat Detection and Prevention \\nAI enhances cybersecurity by detecting and preventing threats, analyzing network traffic, and \\nidentifying vulnerabilities. AI-powered systems automate security tasks, improve threat \\ndetection accuracy, and enhance overall cybersecurity posture.', '\\nAnomaly Detection \\nAI-powered anomaly detection systems identify unusual patterns and behaviors that may \\nindicate a security threat.', 'These systems provide real-time alerts and support rapid response to \\nsecurity incidents.', '\\nFraud Detection \\nAI is used in fraud detection to analyze transactions, identify suspicious activities, and prevent \\nfraudulent actions. AI-powered systems improve accuracy, reduce false positives, and enhance \\nfraud prevention measures.', '\\nVulnerability Management \\n AI helps manage vulnerabilities by identifying and prioritizing security weaknesses in systems and \\nnetworks. AI-powered tools automate vulnerability scanning, assessment, and remediation, \\nreducing the risk of cyberattacks.', '\\nIncident Response \\nAI enhances incident response by automating tasks, analyzing data, and providing insights that \\nsupport rapid and effective response to security incidents.', 'AI-powered systems improve \\nresponse time, minimize damage, and enhance recovery efforts.', '\\nChapter 13: The Social Impact of AI \\nAddressing Societal Challenges \\nAI has the potential to address significant societal challenges, such as climate change, poverty, \\nand healthcare disparities.', 'AI-powered solutions can improve resource management, enhance \\ndecision-making, and support sustainable development.', '\\nAI for Social Good \\nAI for social good initiatives leverage AI to tackle social and environmental problems.', 'These \\nprojects focus on using AI to improve access to education, healthcare, and social services, \\npromoting equity and well-being.', '\\nEthical Considerations \\nAddressing the ethical implications of AI is crucial for ensuring its positive social impact.', 'This \\nincludes promoting fairness, transparency, and accountability in AI systems, as well as protecting \\nprivacy and human rights.', '\\nPublic Perception and Trust \\nPublic perception and trust in AI are essential for its widespread adoption and positive social \\nimpact. Building trust requires transparency, explainability, and responsible development and \\ndeployment of AI systems.', '\\nGlobal Collaboration \\nAddressing the social impact of AI requires global collaboration and cooperation.', 'This includes \\nsharing knowledge, developing standards, and promoting responsible AI practices across \\nborders.', '\\nChapter 14: AI and Smart Cities \\nUrban Planning and Management \\nAI enhances urban planning and management by analyzing data, optimizing resource allocation, \\nand improving city services.', 'AI-powered systems support sustainable urban development, \\nenhance quality of life, and promote efficient city operations. \\nSmart Transportation \\nAI-powered smart transportation systems optimize traffic flow, reduce congestion, and enhance \\npublic transit.', 'These systems use real-time data to manage traffic signals, provide route \\nrecommendations, and support autonomous vehicles.', '\\n Energy Management \\nAI optimizes energy management in smart cities by predicting demand, managing supply, and \\npromoting energy efficiency.', 'AI-powered systems enhance grid stability, reduce energy waste, \\nand support the integration of renewable energy sources.', '\\nPublic Safety and Security \\nAI enhances public safety and security in smart cities by monitoring public spaces, detecting \\nanomalies, and supporting emergency response. AI-powered systems improve crime prevention, \\nenhance situational awareness, and support rapid response to incidents.', '\\nEnvironmental Monitoring \\nAI-powered environmental monitoring systems track air and water quality, detect pollution, and \\nsupport environmental protection efforts.', 'These systems provide real-time data, identify \\npollution sources, and inform environmental policies.', '\\nChapter 15: The Future of AI Research \\nAdvancements in Deep Learning \\nContinued advancements in deep learning are expected to drive further breakthroughs in AI.', '\\nResearch is focused on developing more efficient and interpretable deep learning models, as well \\nas exploring new architectures and training techniques.', '\\nExplainable AI (XAI) \\nExplainable AI (XAI) aims to make AI systems more transparent and understandable.', 'Research in \\nXAI focuses on developing methods for explaining AI decisions, enhancing trust, and improving \\naccountability.', '\\nAI and Neuroscience \\nThe intersection of AI and neuroscience is a promising area of research. Understanding the \\nhuman brain can inspire new AI algorithms and architectures, while AI can provide insights into \\nbrain function and cognition.', '\\nAI Safety and Security \\nEnsuring the safety and security of AI systems is a critical area of research.', 'This includes \\ndeveloping methods for verifying AI behavior, mitigating risks, and preventing unintended \\nconsequences.', '\\nHuman-Centered AI \\nHuman-centered AI focuses on developing AI systems that are aligned with human values, \\nenhance human capabilities, and promote well-being.', 'This involves considering ethical, social, \\nand psychological aspects of AI development and deployment.', '\\n \\n \\n Chapter 16: AI and the Arts \\nGenerative AI and Creativity \\nGenerative AI models, such as Generative Adversarial Networks (GANs) and transformers, are \\ncapable of creating original content, including images, text, and music.', 'These models are pushing \\nthe boundaries of AI-driven creativity and opening up new possibilities for artistic expression.', '\\nAI as a Collaborative Partner \\nAI is increasingly used as a collaborative partner for artists and designers.', 'AI tools can assist with \\ntasks such as ideation, prototyping, and refinement, enhancing the creative process and \\nenabling new forms of expression.', '\\nAI in Music and Sound Design \\nAI is transforming music and sound design by enabling new forms of composition, performance, \\nand production. AI-powered tools can generate melodies, harmonies, and rhythms, create \\ninteractive musical experiences, and assist with audio mixing and mastering.', '\\nAI in Visual Arts and Design \\nAI is used in visual arts and design to generate images, create animations, and assist with design \\nprocesses.', 'AI-powered tools can create realistic images, generate design variations, and \\nautomate repetitive tasks, freeing up artists to focus on creative exploration.', '\\nAI and Interactive Media \\nAI is enhancing interactive media, such as video games and virtual reality experiences, by \\nenabling more realistic and engaging interactions.', 'AI-powered characters, dynamic \\nenvironments, and personalized content create immersive and adaptive experiences.', '\\nChapter 17: AI and the Environment \\nClimate Change Mitigation \\nAI is used to mitigate climate change by optimizing energy consumption, improving renewable \\nenergy integration, and supporting carbon capture and storage.', 'AI-powered systems analyze \\ndata, predict climate impacts, and inform mitigation strategies.', '\\nPrecision Agriculture \\nAI enhances precision agriculture by monitoring crops, optimizing resource use, and predicting \\nyields. AI-powered tools improve farming practices, reduce environmental impact, and enhance \\nfood security.', '\\nWildlife Conservation \\nAI is used in wildlife conservation to monitor populations, track movements, and detect poaching \\nactivities. AI-powered systems analyze data from sensors, cameras, and drones, providing \\ninsights that support conservation efforts.', '\\n \\n \\n Environmental Monitoring \\nAI-powered environmental monitoring systems track air and water quality, detect pollution, and \\nsupport environmental protection efforts.', 'These systems provide real-time data, identify \\npollution sources, and inform environmental policies.', '\\nDisaster Response \\nAI enhances disaster response by analyzing data, predicting impacts, and supporting relief \\nefforts.', 'AI-powered systems improve situational awareness, optimize resource allocation, and \\nenhance coordination among responders.', '\\nChapter 18: The Role of Government and Policy in AI \\nAI Strategy and Policy Frameworks \\nGovernments around the world are developing AI strategies and policy frameworks to guide the \\ndevelopment and deployment of AI.', 'These frameworks address ethical considerations, promote \\ninnovation, and ensure responsible AI practices.', '\\nRegulation of AI \\nThe regulation of AI is a complex and evolving area.', 'Governments are considering regulations to \\naddress issues such as bias, transparency, privacy, and safety.', 'Balancing innovation with ethical \\nconsiderations is a key challenge.', '\\nFunding for AI Research and Development \\nGovernments play a crucial role in funding AI research and development. Public funding supports \\nbasic research, applied research, and the development of AI infrastructure.', 'Government \\ninvestments drive innovation and foster collaboration.', '\\nInternational Cooperation \\nInternational cooperation is essential for addressing the global challenges and opportunities \\npresented by AI.', 'This includes sharing knowledge, developing standards, and promoting \\nresponsible AI practices across borders.', '\\nPublic Engagement and Education \\nEngaging the public in discussions about AI is crucial for building trust and ensuring that AI \\ndevelopment aligns with societal values.', 'Education and awareness campaigns inform the public \\nabout AI, its impacts, and its potential.', '\\nChapter 19: AI and Ethics \\nPrinciples of Ethical AI \\nEthical AI principles guide the development and deployment of AI systems to ensure they are fair, \\ntransparent, accountable, and beneficial to society.', 'Key principles include respect for human \\nrights, privacy, non-discrimination, and beneficence.', '\\n \\n \\n Addressing Bias in AI \\nAI systems can inherit and amplify biases present in the data they are trained on, leading to unfair \\nor discriminatory outcomes.', 'Addressing bias requires careful data collection, algorithm design, \\nand ongoing monitoring and evaluation.', '\\nTransparency and Explainability \\nTransparency and explainability are essential for building trust in AI systems.', 'Explainable AI (XAI) \\ntechniques aim to make AI decisions more understandable, enabling users to assess their \\nfairness and accuracy.', '\\nPrivacy and Data Protection \\nAI systems often rely on large amounts of data, raising concerns about privacy and data \\nprotection.', 'Ensuring responsible data handling, implementing privacy-preserving techniques, \\nand complying with data protection regulations are crucial.', '\\nAccountability and Responsibility \\nEstablishing accountability and responsibility for AI systems is essential for addressing potential \\nharms and ensuring ethical behavior.', 'This includes defining roles and responsibilities for \\ndevelopers, deployers, and users of AI systems.', '\\nChapter 20: Building Trust in AI \\nTransparency and Explainability \\nTransparency and explainability are key to building trust in AI. Making AI systems understandable \\nand providing insights into their decision-making processes helps users assess their reliability \\nand fairness.', '\\nRobustness and Reliability \\nEnsuring that AI systems are robust and reliable is essential for building trust.', 'This includes \\ntesting and validating AI models, monitoring their performance, and addressing potential \\nvulnerabilities.', '\\nUser Control and Agency \\nEmpowering users with control over AI systems and providing them with agency in their \\ninteractions with AI enhances trust.', 'This includes allowing users to customize AI settings, \\nunderstand how their data is used, and opt out of AI-driven features.', '\\nEthical Design and Development \\nIncorporating ethical considerations into the design and development of AI systems is crucial for \\nbuilding trust.', 'This includes conducting ethical impact assessments, engaging stakeholders, and \\nadhering to ethical guidelines and standards.', '\\nPublic Engagement and Education \\nEngaging the public in discussions about AI and educating them about its capabilities, \\nlimitations, and ethical implications helps build trust.', 'Public awareness campaigns, educational \\ninitiatives, and open dialogue foster informed understanding and acceptance.', '\\n Chapter 21: The Path Forward for AI \\nContinued Research and Innovation \\nContinued research and innovation are essential for advancing AI capabilities, addressing its \\nchallenges, and realizing its full potential.', 'This includes investing in basic research, applied \\nresearch, and the development of new AI technologies and applications.', '\\nResponsible Development and Deployment \\nResponsible development and deployment of AI are crucial for ensuring its benefits are widely \\nshared and its risks are mitigated.', 'This involves adhering to ethical principles, promoting fairness \\nand transparency, and protecting human rights and values.', '\\nGlobal Collaboration and Cooperation \\nGlobal collaboration and cooperation are essential for addressing the global challenges and \\nopportunities presented by AI.', 'This includes sharing knowledge, developing standards, and \\npromoting responsible AI practices across borders.', '\\nEducation and Workforce Development \\nPreparing the workforce for the future of AI requires education and training initiatives that equip \\nindividuals with the skills needed to work with AI systems and adapt to new job roles.', 'This \\nincludes promoting STEM education, providing reskilling and upskilling opportunities, and \\nfostering lifelong learning.', '\\nA Human-Centered Approach \\nA human-centered approach to AI focuses on developing AI systems that enhance human \\ncapabilities, promote well-being, and align with human values.', 'This involves considering the \\nethical, social, and psychological impacts of AI and prioritizing human needs and interests.', '\\nBy embracing these principles and working together, we can harness the transformative potential \\nof AI to create a more innovative, equitable, and sustainable future.', 'The path forward requires \\ndedication, collaboration, and a commitment to responsible AI development and deployment.']\n"
          ]
        }
      ],
      "source": [
        "def split_into_chunks(sentences, breakpoints):\n",
        "    \"\"\"\n",
        "    Splits sentences into semantic chunks.\n",
        "\n",
        "    Args:\n",
        "    sentences (List[str]): List of sentences.\n",
        "    breakpoints (List[int]): Indices where chunking should occur.\n",
        "\n",
        "    Returns:\n",
        "    List[str]: List of text chunks.\n",
        "    \"\"\"\n",
        "    chunks = []  # Initialize an empty list to store the chunks\n",
        "    start = 0  # Initialize the start index\n",
        "\n",
        "    # Iterate through each breakpoint to create chunks\n",
        "    for bp in breakpoints:\n",
        "        # Append the chunk of sentences from start to the current breakpoint\n",
        "        chunks.append(\". \".join(sentences[start:bp + 1]) + \".\")\n",
        "        start = bp + 1  # Update the start index to the next sentence after the breakpoint\n",
        "\n",
        "    # Append the remaining sentences as the last chunk\n",
        "    chunks.append(\". \".join(sentences[start:]))\n",
        "    return chunks  # Return the list of chunks\n",
        "\n",
        "# Create chunks using the split_into_chunks function\n",
        "text_chunks = split_into_chunks(sentences, breakpoints)\n",
        "\n",
        "# Print the number of chunks created\n",
        "print(f\"Number of semantic chunks: {len(text_chunks)}\")\n",
        "\n",
        "# Print the first chunk to verify the result\n",
        "print(\"\\nFirst text chunk:\")\n",
        "print(text_chunks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3_fSVVUVale"
      },
      "source": [
        "### Creating Embeddings for Semantic Chunks\n",
        "\n",
        "We create embeddings for each chunk for later retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_ef3kbd6NFAT"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(text_chunks):\n",
        "    \"\"\"\n",
        "    Creates embeddings for each text chunk.\n",
        "\n",
        "    Args:\n",
        "    text_chunks (List[str]): List of text chunks.\n",
        "\n",
        "    Returns:\n",
        "    List[np.ndarray]: List of embedding vectors.\n",
        "    \"\"\"\n",
        "    # Generate embeddings for each text chunk using the get_embedding function\n",
        "    return [embed(chunk) for chunk in text_chunks]\n",
        "\n",
        "# Create chunk embeddings using the create_embeddings function\n",
        "chunk_embeddings = create_embeddings(text_chunks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5X4dV1_NIG5",
        "outputId": "c4734edc-eb1c-48d3-b119-57876851fe6c"
      },
      "outputs": [],
      "source": [
        "# chunk_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIGWMNIeVe8u"
      },
      "source": [
        "### Performing Semantic Search\n",
        "\n",
        "We implement cosine similarity to retrieve the most relevant chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6kMc4i5yNKXf"
      },
      "outputs": [],
      "source": [
        "def semantic_search(query, text_chunks, chunk_embeddings, k=5):\n",
        "    \"\"\"\n",
        "    Finds the most relevant text chunks for a query.\n",
        "\n",
        "    Args:\n",
        "        query (str): Search query.\n",
        "        text_chunks (List[str]): List of text chunks.\n",
        "        chunk_embeddings (List[np.ndarray]): List of chunk embeddings.\n",
        "        k (int): Number of top results to return.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Top-k relevant chunks.\n",
        "    \"\"\"\n",
        "    # Embed the query\n",
        "    query_embedding = embed(query)\n",
        "\n",
        "    # Ensure query_embedding has correct shape (1, dim)\n",
        "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
        "\n",
        "    # Compute cosine similarities\n",
        "    similarities = np.array([\n",
        "        cosine_similarity(query_embedding, emb.reshape(1, -1))[0][0]  # scalar similarity\n",
        "        for emb in chunk_embeddings\n",
        "    ])\n",
        "\n",
        "    # Get top-k indices\n",
        "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
        "\n",
        "    # Return top-k text chunks\n",
        "    return [text_chunks[i] for i in top_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc1IFSThNWV5",
        "outputId": "ee4cee61-78a4-4a59-dc85-972f91ed99d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What is 'Explainable AI' and why is it considered important?\n",
            "Context 1:\n",
            "\n",
            "Explainable AI (XAI) \n",
            "Explainable AI (XAI) aims to make AI systems more transparent and understandable.\n",
            "========================================\n",
            "Context 2:\n",
            "\n",
            "Transparency and Explainability \n",
            "Transparency and explainability are essential for building trust in AI systems.\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "# Load the validation data from a JSON file\n",
        "with open('../data/val.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the first query from the validation data\n",
        "query = data[0]['question']\n",
        "\n",
        "# Get top 2 relevant chunks\n",
        "top_chunks = semantic_search(query, text_chunks, chunk_embeddings, k=2)\n",
        "\n",
        "# Print the query\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Print the top 2 most relevant text chunks\n",
        "for i, chunk in enumerate(top_chunks):\n",
        "    print(f\"Context {i+1}:\\n{chunk}\\n{'='*40}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vmYVtr1VlzF"
      },
      "source": [
        "### Generating a Response Based on Retrieved Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hOqTaVlnPLnr"
      },
      "outputs": [],
      "source": [
        "load_dotenv(\"../conf.env\")\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SCF7-_cpNhH9"
      },
      "outputs": [],
      "source": [
        "# Define the system prompt for the AI assistant\n",
        "system_prompt = \"You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: 'I do not have enough information to answer that.'\"\n",
        "\n",
        "def generate_response(system_prompt, user_message, model=\"gemini-2.5-flash\"):\n",
        "    \"\"\"\n",
        "    Generates a response from the AI model based on the system prompt and user message.\n",
        "\n",
        "    Args:\n",
        "    system_prompt (str): The system prompt to guide the AI's behavior.\n",
        "    user_message (str): The user's message or query.\n",
        "    model (str): The model to be used for generating the response. Default is \"meta-llama/Llama-2-7B-chat-hf\".\n",
        "\n",
        "    Returns:\n",
        "    dict: The response from the AI model.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_message}\n",
        "        ]\n",
        "    )\n",
        "    return response\n",
        "\n",
        "# Create the user prompt based on the top chunks\n",
        "user_prompt = \"\\n\".join([f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\" for i, chunk in enumerate(top_chunks)])\n",
        "user_prompt = f\"{user_prompt}\\nQuestion: {query}\"\n",
        "\n",
        "# Generate AI response\n",
        "ai_response = generate_response(system_prompt, user_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IpDTiNW_P0DT",
        "outputId": "d904193b-5a8c-4e10-bb37-50bd59b3b402"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Explainable AI (XAI) aims to make AI systems more transparent and understandable. It is considered important because transparency and explainability are essential for building trust in AI systems.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_response_text = ai_response.choices[0].message.content\n",
        "ai_response_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzGptA5jVqc8"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22N1eKLYP4LP",
        "outputId": "6b379e5e-03d9-4a6d-e55b-65d0b609a551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score: 0.5\n"
          ]
        }
      ],
      "source": [
        "# Define the system prompt for the evaluation system\n",
        "evaluate_system_prompt = \"You are an intelligent evaluation system tasked with assessing the AI assistant's responses. If the AI assistant's response is very close to the true response, assign a score of 1. If the response is incorrect or unsatisfactory in relation to the true response, assign a score of 0. If the response is partially aligned with the true response, assign a score of 0.5.\"\n",
        "\n",
        "# Create the evaluation prompt by combining the user query, AI response, true response, and evaluation system prompt\n",
        "evaluation_prompt = f\"User Query: {query}\\nAI Response:\\n{ai_response_text}\\nTrue Response: {data[0]['ideal_answer']}\\n{evaluate_system_prompt}\"\n",
        "\n",
        "# Generate the evaluation response using the evaluation system prompt and evaluation prompt\n",
        "evaluation_response = generate_response(evaluate_system_prompt, evaluation_prompt)\n",
        "\n",
        "# Print the evaluation response\n",
        "print(evaluation_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy2ODe1dQS29",
        "outputId": "8b73d49a-53ef-445c-ba8d-104570883539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 768)\n"
          ]
        }
      ],
      "source": [
        "print(embed(ai_response_text).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q57tspD0RzNJ",
        "outputId": "9838de62-06d1-4892-d2d1-1b1f569f43ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 768)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embed(data[0]['ideal_answer']).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8E5wmT2QB67",
        "outputId": "a2784fea-6808-4dea-cfc4-97f61fcd19da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 768) (1, 768)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.99459505]], dtype=float32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ai_gen = embed(ai_response_text) # (1,x)\n",
        "ideal_re = embed(data[0]['ideal_answer']) # (1,x)\n",
        "print(ai_gen.shape, ideal_re.shape)\n",
        "\n",
        "cosine_similarity(ai_gen, ideal_re)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "history_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
