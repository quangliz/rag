{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBOWFRYlx_Ux",
        "outputId": "ed60054d-4fd7-4c8b-b71c-59d0ecc0f111"
      },
      "outputs": [],
      "source": [
        "!pip install pymupdf\n",
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iDjSMhfcx3dX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fitz\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "688e1feee2864052920c8e2ad772fc26",
            "596434b04fc24980ab859c5de10fc350",
            "a842e3cc1aa641df89c96f1a93498b43",
            "ce6bafce454b450599d2401c482626d9",
            "032ee264f65d4650bf6ab90615a4176b",
            "2503dd54ae554a2ba743f907a2818b66",
            "3e23088cc44042ce931772b801f8e2f3",
            "e0893a843737418fa7f2d3bc8cebbc50",
            "b79a033e539a480a9936cfa0464e5bf8",
            "4cbee944a2bc4c6f9b976546d469ddea",
            "3e5092f6b1314f1a9ae248d6afc57d54"
          ]
        },
        "id": "XhUy2wMn23-D",
        "outputId": "710428ef-6dae-4fec-88e0-44c042199e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "688e1feee2864052920c8e2ad772fc26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(\"unsloth/Llama-3.2-3B-Instruct\")\n",
        "gen_model = AutoModelForCausalLM.from_pretrained(\"unsloth/Llama-3.2-3B-Instruct\",\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "embed_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-base-en-v1.5\")\n",
        "embed_model = AutoModel.from_pretrained(\"BAAI/bge-base-en-v1.5\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0qkBEDnG3wnp"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(text):\n",
        "  is_string = isinstance(text, str)\n",
        "  if is_string: text = [text]\n",
        "\n",
        "  try:\n",
        "    inputs = embed_tokenizer(\n",
        "        text,\n",
        "        padding = True,\n",
        "        return_tensors = \"pt\"\n",
        "    ).to(device)\n",
        "  except Exception as e:\n",
        "    print(f\"Tokenizer error: {e}\")\n",
        "    return None\n",
        "\n",
        "  try:\n",
        "    with torch.no_grad():\n",
        "      output = embed_model(**inputs)\n",
        "      cls = output.last_hidden_state[:, 0, :]\n",
        "      embed_normalized = F.normalize(cls, p = 2, dim = 1)\n",
        "    embeddings = [embed.cpu().numpy() for embed in embed_normalized]\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Embedding generation error: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-s6RL_Qi7VpD"
      },
      "outputs": [],
      "source": [
        "def gen(system_prompt, user_prompt, temperature=0):\n",
        "    text = gen_tokenizer.apply_chat_template(\n",
        "        conversation=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    model_inputs = gen_tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    if temperature > 0:\n",
        "        generated_ids = gen_model.generate(\n",
        "            **model_inputs,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            max_new_tokens=1024\n",
        "        )\n",
        "    else:\n",
        "        generated_ids = gen_model.generate(\n",
        "            **model_inputs,\n",
        "            do_sample=False,\n",
        "            temperature= None,\n",
        "            top_p=None,  # disable top_p and temperature to not receive warning\n",
        "            max_new_tokens=1024\n",
        "        )\n",
        "    generated_ids = [\n",
        "        output_ids[len(input_ids):]\n",
        "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "    response = gen_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3CjBEueZ5PPc"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "  pdf = fitz.open(pdf_path)\n",
        "  text = \"\"\n",
        "\n",
        "  for page in pdf:\n",
        "    text += page.get_text()\n",
        "  return text\n",
        "\n",
        "def chunk_text(text, n, overlap):\n",
        "  return [text[i:i+n] for i in range(0, len(text), n - overlap)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mj7p8QyA50uf"
      },
      "outputs": [],
      "source": [
        "class SimpleVectorStore:\n",
        "  def __init__(self):\n",
        "    self.vectors = []\n",
        "    self.texts = []\n",
        "    self.metadata = []\n",
        "\n",
        "  def add_item(self, text, embedding, metadata = None):\n",
        "    self.vectors.append(embedding)\n",
        "    self.texts.append(text)\n",
        "    self.metadata.append(metadata or {})\n",
        "\n",
        "  def similarity_search(self, query_embedding, k = 5):\n",
        "    if not self.vectors: return []\n",
        "\n",
        "    similarities = [(i, cosine_similarity(query_embedding.reshape(1, -1), vector.reshape(1, -1))) for i, vector in enumerate(self.vectors)]\n",
        "\n",
        "    similarities.sort(key=lambda x:x[1], reverse = True)\n",
        "\n",
        "    results = []\n",
        "    for i in range(min(k, len(similarities))):\n",
        "      idx, score = similarities[i]\n",
        "      results.append({\n",
        "          \"text\": self.texts[idx],\n",
        "          \"metadata\": self.metadata[idx],\n",
        "          \"similarity\": score\n",
        "      })\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vCO3G-B17viB"
      },
      "outputs": [],
      "source": [
        "def process_document(pdf_path, chunk_size = 1000, overlap = 200):\n",
        "  print(\"Extracting text...\")\n",
        "  extracted_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "  print(\"Chunking text...\")\n",
        "  text_chunks = chunk_text(extracted_text, chunk_size, overlap)\n",
        "\n",
        "  print(\"Creating embeddings...\")\n",
        "  embeddings = create_embeddings(text_chunks)\n",
        "\n",
        "  store = SimpleVectorStore()\n",
        "\n",
        "  for i, (chunk, embedding) in enumerate(zip(text_chunks, embeddings)):\n",
        "    store.add_item(\n",
        "        text = chunk,\n",
        "        embedding = embedding, # nda(dim,)\n",
        "        metadata = {\n",
        "            \"index\":i,\n",
        "            \"source\": pdf_path\n",
        "        }\n",
        "    )\n",
        "\n",
        "  print(f\"Added {len(text_chunks)} chunks to the vector store\")\n",
        "\n",
        "  return store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_NI7Uilu9QBQ"
      },
      "outputs": [],
      "source": [
        "def compress_chunk(chunk, query, compression_type = \"selective\"):\n",
        "  if compression_type == \"selective\":\n",
        "      system_prompt = \"\"\"You are an expert at information filtering.\n",
        "      Your task is to analyze a document chunk and extract ONLY the sentences or paragraphs that are directly\n",
        "      relevant to the user's query. Remove all irrelevant content.\n",
        "\n",
        "      Your output should:\n",
        "      1. ONLY include text that helps answer the query\n",
        "      2. Preserve the exact wording of relevant sentences (do not paraphrase)\n",
        "      3. Maintain the original order of the text\n",
        "      4. Include ALL relevant content, even if it seems redundant\n",
        "      5. EXCLUDE any text that isn't relevant to the query\n",
        "\n",
        "      Format your response as plain text with no additional comments.\"\"\"\n",
        "  elif compression_type == \"summary\":\n",
        "      system_prompt = \"\"\"You are an expert at summarization.\n",
        "      Your task is to create a concise summary of the provided chunk that focuses ONLY on\n",
        "      information relevant to the user's query.\n",
        "\n",
        "      Your output should:\n",
        "      1. Be brief but comprehensive regarding query-relevant information\n",
        "      2. Focus exclusively on information related to the query\n",
        "      3. Omit irrelevant details\n",
        "      4. Be written in a neutral, factual tone\n",
        "\n",
        "      Format your response as plain text with no additional comments.\"\"\"\n",
        "  else:  # extraction\n",
        "      system_prompt = \"\"\"You are an expert at information extraction.\n",
        "      Your task is to extract ONLY the exact sentences from the document chunk that contain information relevant\n",
        "      to answering the user's query.\n",
        "\n",
        "      Your output should:\n",
        "      1. Include ONLY direct quotes of relevant sentences from the original text\n",
        "      2. Preserve the original wording (do not modify the text)\n",
        "      3. Include ONLY sentences that directly relate to the query\n",
        "      4. Separate extracted sentences with newlines\n",
        "      5. Do not add any commentary or additional text\n",
        "\n",
        "      Format your response as plain text with no additional comments.\"\"\"\n",
        "\n",
        "  user_prompt = f\"\"\"\n",
        "      Query: {query}\n",
        "\n",
        "      Document Chunk:\n",
        "      {chunk}\n",
        "\n",
        "      Extract only the content relevant to answering this query.\n",
        "  \"\"\"\n",
        "  compressed_chunk = gen(system_prompt, user_prompt) #str\n",
        "\n",
        "  original_length = len(chunk)\n",
        "  compressed_length = len(compressed_chunk)\n",
        "  compression_ratio = (original_length - compressed_length) / original_length * 100\n",
        "\n",
        "  print(f\"\"\"\n",
        "  ===Chunk: {chunk[:20]}\n",
        "  ===Compressed: {compressed_chunk}\n",
        "  ===Compressed length: {compressed_length}\n",
        "  =============================================\n",
        "  \"\"\")\n",
        "\n",
        "  return compressed_chunk, compression_ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kTOGmURy-LGY"
      },
      "outputs": [],
      "source": [
        "def generate_response(query, context):\n",
        "    \"\"\"\n",
        "    Generate a response based on the query and context.\n",
        "\n",
        "    Args:\n",
        "        query (str): User query\n",
        "        context (str): Context text from compressed chunks\n",
        "        model (str): LLM model to use\n",
        "\n",
        "    Returns:\n",
        "        str: Generated response\n",
        "    \"\"\"\n",
        "    # Define the system prompt to guide the AI's behavior\n",
        "    system_prompt = \"\"\"You are a helpful AI assistant. Answer the user's question based only on the provided context.\n",
        "    If you cannot find the answer in the context, state that you don't have enough information.\"\"\"\n",
        "\n",
        "    # Create the user prompt by combining the context and the query\n",
        "    user_prompt = f\"\"\"\n",
        "        Context:\n",
        "        {context}\n",
        "\n",
        "        Question: {query}\n",
        "\n",
        "        Please provide a comprehensive answer based only on the context above.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a response using the OpenAI API\n",
        "    response = gen(system_prompt, user_prompt)\n",
        "\n",
        "    # Return the generated response content\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "CNG5WnLz_253"
      },
      "outputs": [],
      "source": [
        "def rag_with_compression(pdf_path, query, k=10, compression_type=\"selective\", model=\"meta-llama/Llama-3.2-3B-Instruct\"):\n",
        "    \"\"\"\n",
        "    Complete RAG pipeline with contextual compression.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to PDF document\n",
        "        query (str): User query\n",
        "        k (int): Number of chunks to retrieve initially\n",
        "        compression_type (str): Type of compression\n",
        "        model (str): LLM model to use\n",
        "\n",
        "    Returns:\n",
        "        dict: Results including query, compressed chunks, and response\n",
        "    \"\"\"\n",
        "    print(\"\\n=== RAG WITH CONTEXTUAL COMPRESSION ===\")\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"Compression type: {compression_type}\")\n",
        "\n",
        "    # Process the document to extract text, chunk it, and create embeddings\n",
        "    vector_store = process_document(pdf_path)\n",
        "\n",
        "    # Create an embedding for the query\n",
        "    query_embedding = create_embeddings(query)[0] # nda(dim,)\n",
        "\n",
        "    # Retrieve the top k most similar chunks based on the query embedding\n",
        "    print(f\"Retrieving top {k} chunks...\")\n",
        "    results = vector_store.similarity_search(query_embedding, k=k)\n",
        "    retrieved_chunks = [result[\"text\"] for result in results]\n",
        "\n",
        "    # Apply compression to the retrieved chunks\n",
        "    compressed_results = [compress_chunk(retrieved_chunk, query, compression_type) for retrieved_chunk in retrieved_chunks]\n",
        "    compressed_chunks = [result[0] for result in compressed_results]\n",
        "    compression_ratios = [result[1] for result in compressed_results]\n",
        "\n",
        "    # Filter out any empty compressed chunks\n",
        "    filtered_chunks = [(chunk, ratio) for chunk, ratio in zip(compressed_chunks, compression_ratios) if chunk.strip()]\n",
        "\n",
        "    if not filtered_chunks:\n",
        "        # If all chunks are compressed to empty strings, use the original chunks\n",
        "        print(\"Warning: All chunks were compressed to empty strings. Using original chunks.\")\n",
        "        filtered_chunks = [(chunk, 0.0) for chunk in retrieved_chunks]\n",
        "    else:\n",
        "        compressed_chunks, compression_ratios = zip(*filtered_chunks)\n",
        "\n",
        "    # Generate context from the compressed chunks\n",
        "    context = \"\\n\\n---\\n\\n\".join(compressed_chunks)\n",
        "\n",
        "    # Generate a response based on the compressed chunks\n",
        "    print(\"Generating response based on compressed chunks...\")\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    # Prepare the result dictionary\n",
        "    result = {\n",
        "        \"query\": query,\n",
        "        \"original_chunks\": retrieved_chunks,\n",
        "        \"compressed_chunks\": compressed_chunks,\n",
        "        \"compression_ratios\": compression_ratios,\n",
        "        \"context_length_reduction\": f\"{sum(compression_ratios)/len(compression_ratios):.2f}%\",\n",
        "        \"response\": response\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== RESPONSE ===\")\n",
        "    print(response)\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HhnJ7fXaCqqw"
      },
      "outputs": [],
      "source": [
        "def standard_rag(pdf_path, query, k=10):\n",
        "    \"\"\"\n",
        "    Standard RAG without compression.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to PDF document\n",
        "        query (str): User query\n",
        "        k (int): Number of chunks to retrieve\n",
        "        model (str): LLM model to use\n",
        "\n",
        "    Returns:\n",
        "        dict: Results including query, chunks, and response\n",
        "    \"\"\"\n",
        "    print(\"\\n=== STANDARD RAG ===\")\n",
        "    print(f\"Query: {query}\")\n",
        "\n",
        "    # Process the document to extract text, chunk it, and create embeddings\n",
        "    vector_store = process_document(pdf_path)\n",
        "\n",
        "    # Create an embedding for the query\n",
        "    query_embedding = create_embeddings(query)[0]\n",
        "\n",
        "    # Retrieve the top k most similar chunks based on the query embedding\n",
        "    print(f\"Retrieving top {k} chunks...\")\n",
        "    results = vector_store.similarity_search(query_embedding, k=k)\n",
        "    retrieved_chunks = [result[\"text\"] for result in results]\n",
        "\n",
        "    # Generate context from the retrieved chunks\n",
        "    context = \"\\n\\n---\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "    # Generate a response based on the retrieved chunks\n",
        "    print(\"Generating response...\")\n",
        "    response = generate_response(query, context)\n",
        "\n",
        "    # Prepare the result dictionary\n",
        "    result = {\n",
        "        \"query\": query,\n",
        "        \"chunks\": retrieved_chunks,\n",
        "        \"response\": response\n",
        "    }\n",
        "\n",
        "    print(\"\\n=== RESPONSE ===\")\n",
        "    print(response)\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3ohL_JVIC7hC"
      },
      "outputs": [],
      "source": [
        "def evaluate_responses(query, responses, reference_answer):\n",
        "    \"\"\"\n",
        "    Evaluate multiple responses against a reference answer.\n",
        "\n",
        "    Args:\n",
        "        query (str): User query\n",
        "        responses (Dict[str, str]): Dictionary of responses by method\n",
        "        reference_answer (str): Reference answer\n",
        "\n",
        "    Returns:\n",
        "        str: Evaluation text\n",
        "    \"\"\"\n",
        "    # Define the system prompt to guide the AI's behavior for evaluation\n",
        "    system_prompt = \"\"\"You are an objective evaluator of RAG responses. Compare different responses to the same query\n",
        "    and determine which is most accurate, comprehensive, and relevant to the query.\"\"\"\n",
        "\n",
        "    # Create the user prompt by combining the query and reference answer\n",
        "    user_prompt = f\"\"\"\n",
        "    Query: {query}\n",
        "\n",
        "    Reference Answer: {reference_answer}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Add each response to the prompt\n",
        "    for method, response in responses.items():\n",
        "        user_prompt += f\"\\n{method.capitalize()} Response:\\n{response}\\n\"\n",
        "\n",
        "    # Add the evaluation criteria to the user prompt\n",
        "    user_prompt += \"\"\"\n",
        "    Please evaluate these responses based on:\n",
        "    1. Factual accuracy compared to the reference\n",
        "    2. Comprehensiveness - how completely they answer the query\n",
        "    3. Conciseness - whether they avoid irrelevant information\n",
        "    4. Overall quality\n",
        "\n",
        "    Rank the responses from best to worst with detailed explanations.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate an evaluation response using the OpenAI API\n",
        "    evaluation_response = gen(system_prompt, user_prompt)\n",
        "\n",
        "    # Return the evaluation text from the response\n",
        "    return evaluation_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NM-6PZyhDCY7"
      },
      "outputs": [],
      "source": [
        "def evaluate_compression(pdf_path, query, reference_answer=None, compression_types=[\"selective\", \"summary\", \"extraction\"]):\n",
        "    \"\"\"\n",
        "    Compare different compression techniques with standard RAG.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to PDF document\n",
        "        query (str): User query\n",
        "        reference_answer (str): Optional reference answer\n",
        "        compression_types (List[str]): Compression types to evaluate\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation results\n",
        "    \"\"\"\n",
        "    print(\"\\n=== EVALUATING CONTEXTUAL COMPRESSION ===\")\n",
        "    print(f\"Query: {query}\")\n",
        "\n",
        "    # Run standard RAG without compression\n",
        "    standard_result = standard_rag(pdf_path, query)\n",
        "\n",
        "    # Dictionary to store results of different compression techniques\n",
        "    compression_results = {}\n",
        "\n",
        "    # Run RAG with each compression technique\n",
        "    for comp_type in compression_types:\n",
        "        print(f\"\\nTesting {comp_type} compression...\")\n",
        "        compression_results[comp_type] = rag_with_compression(pdf_path, query, compression_type=comp_type)\n",
        "\n",
        "    # Gather responses for evaluation\n",
        "    responses = {\n",
        "        \"standard\": standard_result[\"response\"]\n",
        "    }\n",
        "    for comp_type in compression_types:\n",
        "        responses[comp_type] = compression_results[comp_type][\"response\"]\n",
        "\n",
        "    # Evaluate responses if a reference answer is provided\n",
        "    if reference_answer:\n",
        "        evaluation = evaluate_responses(query, responses, reference_answer)\n",
        "        print(\"\\n=== EVALUATION RESULTS ===\")\n",
        "        print(evaluation)\n",
        "    else:\n",
        "        evaluation = \"No reference answer provided for evaluation.\"\n",
        "\n",
        "    # Calculate metrics for each compression type\n",
        "    metrics = {}\n",
        "    for comp_type in compression_types:\n",
        "        metrics[comp_type] = {\n",
        "            \"avg_compression_ratio\": f\"{sum(compression_results[comp_type]['compression_ratios'])/len(compression_results[comp_type]['compression_ratios']):.2f}%\",\n",
        "            \"total_context_length\": len(\"\\n\\n\".join(compression_results[comp_type]['compressed_chunks'])),\n",
        "            \"original_context_length\": len(\"\\n\\n\".join(standard_result['chunks']))\n",
        "        }\n",
        "\n",
        "    # Return the evaluation results, responses, and metrics\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"responses\": responses,\n",
        "        \"evaluation\": evaluation,\n",
        "        \"metrics\": metrics,\n",
        "        \"standard_result\": standard_result,\n",
        "        \"compression_results\": compression_results\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXyD-krdDH9m",
        "outputId": "8bafcc9a-38e3-46be-e702-c56bcd2af7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== EVALUATING CONTEXTUAL COMPRESSION ===\n",
            "Query: What are the ethical concerns surrounding the use of AI in decision-making?\n",
            "\n",
            "=== STANDARD RAG ===\n",
            "Query: What are the ethical concerns surrounding the use of AI in decision-making?\n",
            "Extracting text...\n",
            "Chunking text...\n",
            "Creating embeddings...\n",
            "Added 42 chunks to the vector store\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieving top 10 chunks...\n",
            "Generating response...\n",
            "\n",
            "=== RESPONSE ===\n",
            "Based on the provided context, the ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "1. **Bias and Fairness**: AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair or discriminatory outcomes. Ensuring fairness and mitigating bias in AI systems is a critical challenge.\n",
            "2. **Transparency and Explainability**: Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to understand how they arrive at their decisions. Enhancing transparency and explainability is crucial for building trust and accountability.\n",
            "3. **Robustness and Reliability**: Ensuring that AI systems are robust and reliable is essential for building trust. This includes testing and validating AI models, monitoring their performance, and addressing potential vulnerabilities.\n",
            "4. **User Control and Agency**: Empowering users with control over AI systems and providing them with agency in their interactions with AI enhances trust. This includes allowing users to customize AI settings, understand how their data is used, and opt out of AI-driven features.\n",
            "5. **Ethical Design and Development**: Incorporating ethical considerations into the design and development of AI systems is crucial for building trust. This includes conducting ethical impact assessments, engaging stakeholders, and adhering to ethical guidelines and standards.\n",
            "6. **Addressing Bias in AI**: AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair or discriminatory outcomes. Addressing bias requires careful data collection, algorithm design, and ongoing monitoring and evaluation.\n",
            "7. **Transparency and Explainability**: Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) techniques aim to make AI decisions more understandable, enabling users to assess their fairness and accuracy.\n",
            "8. **Privacy and Data Protection**: AI systems often rely on large amounts of data, raising concerns about privacy and data security. Protecting sensitive information and ensuring responsible data handling are essential.\n",
            "9. **Accountability and Responsibility**: Establishing accountability and responsibility for AI systems is essential for addressing potential harms and ensuring ethical behavior. This includes defining roles and responsibilities for developers, deployers, and users of AI systems.\n",
            "\n",
            "These concerns highlight the need for responsible AI development and deployment, emphasizing the importance of transparency, explainability, fairness, and accountability in AI decision-making processes.\n",
            "\n",
            "Testing selective compression...\n",
            "\n",
            "=== RAG WITH CONTEXTUAL COMPRESSION ===\n",
            "Query: What are the ethical concerns surrounding the use of AI in decision-making?\n",
            "Compression type: selective\n",
            "Extracting text...\n",
            "Chunking text...\n",
            "Creating embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 42 chunks to the vector store\n",
            "Retrieving top 10 chunks...\n",
            "\n",
            "  ===Chunk:  experiences. AI alg \n",
            "  ===Compressed: The rapid development and deployment of AI raise significant ethical and societal concerns.\n",
            "These concerns include: \n",
            "Bias and Fairness \n",
            "AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
            "Ensuring fairness and mitigating bias in AI systems is a critical challenge.\n",
            "Transparency and Explainability \n",
            "Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to understand how they arrive at their decisions.\n",
            "Enhancing transparency and explainability is crucial.\n",
            "  ===Compressed length: 569\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: to building trust in \n",
            "  ===Compressed: Ensuring that AI systems are robust and reliable is essential for building trust. This includes testing and validating AI models, monitoring their performance, and addressing potential vulnerabilities. Empowering users with control over AI systems and providing them with agency in their interactions with AI enhances trust. This includes allowing users to customize AI settings, understand how their data is used, and opt out of AI-driven features. Incorporating ethical considerations into the design and development of AI systems is crucial for building trust. This includes conducting ethical impact assessments, engaging stakeholders, and adhering to ethical guidelines and standards.\n",
            "  ===Compressed length: 689\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: ance productivity. \n",
            " \n",
            "  ===Compressed: AI is increasingly being used to address social and environmental challenges, such as climate \n",
            "change, poverty, and healthcare disparities. AI for social good initiatives aim to leverage AI for \n",
            "positive impact. Regulation and Governance \n",
            "As AI becomes more pervasive, there will be a growing need for regulation and governance to \n",
            "ensure responsible development and deployment. This includes establishing ethical guidelines, \n",
            "addressing \n",
            "bias \n",
            "and \n",
            "fairness, \n",
            "and \n",
            "protecting \n",
            "privacy \n",
            "and \n",
            "security. International collaborations on standards will be important.\n",
            "  ===Compressed length: 562\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: inability \n",
            "Many AI s \n",
            "  ===Compressed: Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to \n",
            "understand how they arrive at their decisions. Enhancing transparency and explainability is \n",
            "crucial for building trust and accountability.\n",
            "\n",
            "AI systems often rely on large amounts of data, raising concerns about privacy and data security. \n",
            "Protecting sensitive information and ensuring responsible data handling are essential.\n",
            "\n",
            "The automation capabilities of AI have raised concerns about job displacement, particularly in \n",
            "industries with repetitive or routine tasks. Addressing the potential economic and social impacts \n",
            "of AI-driven automation is a key challenge.\n",
            "\n",
            "Establishing clear guidelines and ethical frameworks for AI development and deployment is crucial.\n",
            "  ===Compressed length: 761\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: control, accountabil \n",
            "  ===Compressed: The potential use of AI in autonomous weapons systems raises significant ethical and security concerns.\n",
            "International discussions and regulations are needed to address the risks associated with AI-powered weapons.\n",
            "Establishing clear guidelines and ethical frameworks for AI development and deployment is crucial.\n",
            "Explainable AI (XAI) aims to make AI systems more transparent and understandable.\n",
            "XAI techniques are being developed to provide insights into how AI models make decisions, enhancing trust and accountability.\n",
            "  ===Compressed length: 520\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: nt aligns with socie \n",
            "  ===Compressed: Ethical AI principles guide the development and deployment of AI systems to ensure they are fair, \n",
            "transparent, accountable, and beneficial to society. Key principles include respect for human rights, \n",
            "privacy, non-discrimination, and beneficence. AI systems can inherit and amplify biases present in the \n",
            "data they are trained on, leading to unfair or discriminatory outcomes. Addressing bias requires careful data \n",
            "collection, algorithm design, and ongoing monitoring and evaluation. Transparency and explainability are essential \n",
            "for building trust in AI systems. Explainable AI (XAI) techniques aim to make AI decisions more understandable, \n",
            "enabling users to assess their fairness and accuracy.\n",
            "  ===Compressed length: 699\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: systems. Explainable \n",
            "  ===Compressed: ystems. Explainable AI (XAI) \n",
            "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
            "fairness and accuracy. \n",
            "Transparency and Explainability \n",
            "Transparency and explainability are key to building trust in AI. Making AI systems understandable \n",
            "and providing insights into their decision-making processes helps users assess their reliability \n",
            "and fairness.\n",
            "  ===Compressed length: 386\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: collaboration betwee \n",
            "  ===Compressed: What are the ethical concerns surrounding the use of AI in decision-making?\n",
            "\n",
            "Addressing the ethical implications of AI in the workplace is crucial. This includes ensuring fairness, transparency, and accountability in AI systems, as well as protecting worker rights and privacy.\n",
            "  ===Compressed length: 277\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: \n",
            "privacy and human r \n",
            "  ===Compressed: Public perception and trust in AI are essential for its widespread adoption and positive social impact. Building trust requires transparency, explainability, and responsible development and deployment of AI systems. Addressing the social impact of AI requires global collaboration and cooperation. This includes sharing knowledge, developing standards, and promoting responsible AI practices across borders.\n",
            "  ===Compressed length: 407\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: odels make decisions \n",
            "  ===Compressed: What are the ethical concerns surrounding the use of AI in decision-making?\n",
            "\n",
            "AI at the Edge \n",
            "This approach reduces latency, improves privacy, and enables AI applications in environments with limited connectivity.\n",
            "\n",
            "Human-AI Collaboration \n",
            "The future of AI is likely to involve increased collaboration between humans and AI systems. This includes developing AI tools that augment human capabilities, support decision-making, and enhance productivity.\n",
            "\n",
            "AI for Social Good \n",
            "AI is increasingly being used to address social and environmental challenges, such as climate change, poverty, and healthcare disparities.\n",
            "  ===Compressed length: 608\n",
            "  =============================================\n",
            "  \n",
            "Generating response based on compressed chunks...\n",
            "\n",
            "=== RESPONSE ===\n",
            "The ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "1. Bias and Fairness: AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair or discriminatory outcomes. Ensuring fairness and mitigating bias in AI systems is a critical challenge.\n",
            "\n",
            "2. Transparency and Explainability: Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to understand how they arrive at their decisions. Enhancing transparency and explainability is crucial for building trust and accountability.\n",
            "\n",
            "3. Privacy and Data Security: AI systems often rely on large amounts of data, raising concerns about privacy and data security. Protecting sensitive information and ensuring responsible data handling are essential.\n",
            "\n",
            "4. Job Displacement: The automation capabilities of AI have raised concerns about job displacement, particularly in industries with repetitive or routine tasks. Addressing the potential economic and social impacts of AI-driven automation is a key challenge.\n",
            "\n",
            "5. Accountability: AI systems can make decisions that have significant consequences, but it can be difficult to hold them accountable for these decisions. Enhancing transparency and explainability can help address this concern.\n",
            "\n",
            "6. Social Impact: AI is increasingly being used to address social and environmental challenges, but its impact can be far-reaching and unpredictable. Addressing the social impact of AI requires global collaboration and cooperation to ensure that its benefits are equitably distributed.\n",
            "\n",
            "7. Autonomous Weapons: The potential use of AI in autonomous weapons systems raises significant ethical and security concerns. International discussions and regulations are needed to address the risks associated with AI-powered weapons.\n",
            "\n",
            "8. Human-AI Collaboration: As AI becomes more integrated into various aspects of life, there is a growing need for guidelines and frameworks that ensure humans and AI systems work together effectively and safely.\n",
            "\n",
            "These are the key ethical concerns surrounding the use of AI in decision-making, as highlighted in the provided context.\n",
            "\n",
            "Testing summary compression...\n",
            "\n",
            "=== RAG WITH CONTEXTUAL COMPRESSION ===\n",
            "Query: What are the ethical concerns surrounding the use of AI in decision-making?\n",
            "Compression type: summary\n",
            "Extracting text...\n",
            "Chunking text...\n",
            "Creating embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 42 chunks to the vector store\n",
            "Retrieving top 10 chunks...\n",
            "\n",
            "  ===Chunk:  experiences. AI alg \n",
            "  ===Compressed: The ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "Bias and Fairness: AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
            "Transparency and Explainability: Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to understand how they arrive at their decisions.\n",
            "  ===Compressed length: 397\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: to building trust in \n",
            "  ===Compressed: The ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "- Ensuring AI systems are robust and reliable\n",
            "- Empowering users with control over AI systems\n",
            "- Incorporating ethical considerations into the design and development of AI systems\n",
            "- Conducting ethical impact assessments and engaging stakeholders\n",
            "- Providing insights into AI decision-making processes to assess reliability and fairne\n",
            "  ===Compressed length: 408\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: ance productivity. \n",
            " \n",
            "  ===Compressed: Ethical concerns surrounding AI in decision-making include:\n",
            "\n",
            "* Establishing ethical guidelines\n",
            "* Addressing bias\n",
            "* Ensuring fairness\n",
            "* Protecting privacy\n",
            "* Protecting security\n",
            "\n",
            "These concerns are particularly relevant as AI becomes more pervasive and is used to address social and environmental challenges.\n",
            "  ===Compressed length: 306\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: inability \n",
            "Many AI s \n",
            "  ===Compressed: The ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "- Lack of transparency and explainability, making it difficult to understand how AI systems arrive at their decisions\n",
            "- Privacy and data security concerns due to the reliance on large amounts of data\n",
            "- Job displacement, particularly in industries with repetitive or routine tasks\n",
            "- Autonomy and control issues, including the potential for unintended consequences and establishing clear guidelines for AI development and deployment\n",
            "- The risk of the weaponization of AI\n",
            "  ===Compressed length: 544\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: control, accountabil \n",
            "  ===Compressed: The use of AI in decision-making raises ethical concerns regarding control, accountability, and potential unintended consequences. Establishing clear guidelines and ethical frameworks for AI development and deployment is crucial. The potential use of AI in autonomous weapons systems raises significant ethical and security concerns, necessitating international discussions and regulations to address the associated risks. Explainable AI (XAI) aims to make AI systems more transparent and understandable, enhancing trust and accountability.\n",
            "  ===Compressed length: 540\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: nt aligns with socie \n",
            "  ===Compressed: The ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "- Respect for human rights\n",
            "- Non-discrimination\n",
            "- Privacy\n",
            "- Bias, which can be addressed through careful data collection, algorithm design, and ongoing monitoring and evaluation\n",
            "- Transparency and explainability of AI decisio\n",
            "  ===Compressed length: 301\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: systems. Explainable \n",
            "  ===Compressed: Ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "- Privacy and Data Protection: Ensuring responsible data handling, implementing privacy-preserving techniques, and complying with data protection regulations.\n",
            "- Accountability and Responsibility: Establishing accountability and responsibility for AI systems, defining roles and responsibilities for developers, deployers, and users.\n",
            "- Transparency and Explainability: Providing insights into AI decision-making processes to assess reliability and fairness, and making AI systems understandable.\n",
            "  ===Compressed length: 566\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: collaboration betwee \n",
            "  ===Compressed: The use of AI in decision-making raises ethical concerns, including ensuring fairness, transparency, and accountability in AI systems, as well as protecting worker rights and privacy.\n",
            "  ===Compressed length: 183\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: \n",
            "privacy and human r \n",
            "  ===Compressed: The ethical concerns surrounding the use of AI in decision-making include privacy and human rights, as well as public perception and trust. Building trust requires transparency, explainability, and responsible development and deployment of AI systems.\n",
            "  ===Compressed length: 251\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: odels make decisions \n",
            "  ===Compressed: The ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "* Ensuring accountability in AI-driven decision-making processes\n",
            "* Balancing the benefits of AI with potential risks and unintended consequences\n",
            "* Addressing issues related to bias and fairness in AI decision-making systems\n",
            "* Mitigating the impact of AI on human jobs and societal changes\n",
            "* Ensuring transparency and explainability in AI decision-making processe\n",
            "  ===Compressed length: 438\n",
            "  =============================================\n",
            "  \n",
            "Generating response based on compressed chunks...\n",
            "\n",
            "=== RESPONSE ===\n",
            "The ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "1. Bias and Fairness: AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
            "2. Transparency and Explainability: Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to understand how they arrive at their decisions.\n",
            "3. Privacy and Data Security: The reliance on large amounts of data raises concerns about data protection and security.\n",
            "4. Job Displacement: AI has the potential to displace jobs, particularly in industries with repetitive or routine tasks.\n",
            "5. Autonomy and Control Issues: There are concerns about the potential for unintended consequences and establishing clear guidelines for AI development and deployment.\n",
            "6. Accountability and Responsibility: Establishing accountability and responsibility for AI systems is crucial.\n",
            "7. Respect for Human Rights: AI systems must respect human rights and avoid discrimination.\n",
            "8. Non-Discrimination: AI systems should not perpetuate or exacerbate existing social inequalities.\n",
            "9. Public Perception and Trust: Building trust requires transparency, explainability, and responsible development and deployment of AI systems.\n",
            "\n",
            "These concerns are particularly relevant as AI becomes more pervasive and is used to address social and environmental challenges.\n",
            "\n",
            "Testing extraction compression...\n",
            "\n",
            "=== RAG WITH CONTEXTUAL COMPRESSION ===\n",
            "Query: What are the ethical concerns surrounding the use of AI in decision-making?\n",
            "Compression type: extraction\n",
            "Extracting text...\n",
            "Chunking text...\n",
            "Creating embeddings...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 42 chunks to the vector store\n",
            "Retrieving top 10 chunks...\n",
            "\n",
            "  ===Chunk:  experiences. AI alg \n",
            "  ===Compressed: The rapid development and deployment of AI raise significant ethical and societal concerns.\n",
            "Bias and Fairness\n",
            "AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
            "Ensuring fairness and mitigating bias in AI systems is a critical challenge.\n",
            "Transparency and Explainability\n",
            "Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to understand how they arrive at their decisions.\n",
            "  ===Compressed length: 488\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: to building trust in \n",
            "  ===Compressed: Making AI systems understandable and providing insights into their decision-making processes helps users assess their reliability and fairness.\n",
            "Ensuring that AI systems are robust and reliable is essential for building trust.\n",
            "Empowering users with control over AI systems and providing them with agency in their interactions with AI enhances trust.\n",
            "Incorporating ethical considerations into the design and development of AI systems is crucial for building trust.\n",
            "  ===Compressed length: 462\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: ance productivity. \n",
            " \n",
            "  ===Compressed: AI is increasingly being used to address social and environmental challenges, such as climate change, poverty, and healthcare disparities. \n",
            "\n",
            "This includes establishing ethical guidelines, addressing bias and fairness, and protecting privacy and security.\n",
            "  ===Compressed length: 254\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: inability \n",
            "Many AI s \n",
            "  ===Compressed: Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to \n",
            "understand how they arrive at their decisions.\n",
            " \n",
            "Enhancing transparency and explainability is \n",
            "crucial for building trust and accountability.\n",
            "\n",
            "Establishing clear guidelines and ethical frameworks for \n",
            "AI development and deployment is crucial.\n",
            "  ===Compressed length: 337\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: control, accountabil \n",
            "  ===Compressed: The potential use of AI in autonomous weapons systems raises significant ethical and security concerns.\n",
            "International discussions and regulations are needed to address the risks associated with AI-powered weapons.\n",
            "Explainable AI (XAI) aims to make AI systems more transparent and understandable.\n",
            "XAI techniques are being developed to provide insights into how AI models make decisions, enhancing trust and accountability.\n",
            "  ===Compressed length: 421\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: nt aligns with socie \n",
            "  ===Compressed: Ethical AI principles guide the development and deployment of AI systems to ensure they are fair, \n",
            "transparent, accountable, and beneficial to society. \n",
            "Key principles include respect for human rights, privacy, non-discrimination, and beneficence. \n",
            "Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \n",
            "techniques aim to make AI decisions more understandable, enabling users to assess their fairness and accuracy.\n",
            "  ===Compressed length: 461\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: systems. Explainable \n",
            "  ===Compressed: ystems. Explainable AI (XAI) techniques aim to make AI decisions more understandable, enabling users to assess their fairness and accuracy.\n",
            "Privacy and Data Protection \n",
            "AI systems often rely on large amounts of data, raising concerns about privacy and data protection. Ensuring responsible data handling, implementing privacy-preserving techniques, and complying with data protection regulations are crucial.\n",
            "Establishing accountability and responsibility for AI systems is essential for addressing potential harms and ensuring ethical behavior. This includes defining roles and responsibilities for developers, deployers, and users of AI systems.\n",
            "Transparency and Explainability \n",
            "Transparency and explainability are key to building trust in AI. Making AI systems understandable and providing insights into their decision-making processes helps users assess their reliability and fairness.\n",
            "  ===Compressed length: 889\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: collaboration betwee \n",
            "  ===Compressed: Addressing the ethical implications of AI in the workplace is crucial. \n",
            "\n",
            "This includes ensuring fairness, transparency, and accountability in AI systems, as well as protecting worker rights and privacy.\n",
            "  ===Compressed length: 202\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: \n",
            "privacy and human r \n",
            "  ===Compressed: Building trust requires transparency, explainability, and responsible development and deployment of AI systems.\n",
            "Addressing the social impact of AI requires global collaboration and cooperation.\n",
            "  ===Compressed length: 193\n",
            "  =============================================\n",
            "  \n",
            "\n",
            "  ===Chunk: odels make decisions \n",
            "  ===Compressed: AI at the Edge \n",
            "AI at the edge involves processing data locally on devices, rather than relying on cloud-based \n",
            "servers. This approach reduces latency, improves privacy, and enables AI applications in \n",
            "environments with limited connectivity. \n",
            "\n",
            "Human-AI Collaboration \n",
            "The future of AI is likely to involve increased collaboration between humans and AI systems. This \n",
            "includes developing AI tools that augment human capabilities, support decision-making, and \n",
            "enhance productivity. \n",
            "\n",
            "AI for Social Good \n",
            "AI is increasingly being used to address social and environmental challenges, such as climate \n",
            "change, poverty, and healthcare disparities.\n",
            "  ===Compressed length: 642\n",
            "  =============================================\n",
            "  \n",
            "Generating response based on compressed chunks...\n",
            "\n",
            "=== RESPONSE ===\n",
            "The ethical concerns surrounding the use of AI in decision-making include:\n",
            "\n",
            "1. **Bias and Fairness**: AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
            "2. **Lack of Transparency and Explainability**: Many AI systems, particularly deep learning models, are \"black boxes,\" making it difficult to understand how they arrive at their decisions, which can lead to a lack of trust and accountability.\n",
            "3. **Privacy and Data Protection**: AI systems often rely on large amounts of data, raising concerns about privacy and data protection, and ensuring responsible data handling, implementing privacy-preserving techniques, and complying with data protection regulations.\n",
            "4. **Accountability and Responsibility**: Establishing accountability and responsibility for AI systems is essential for addressing potential harms and ensuring ethical behavior, including defining roles and responsibilities for developers, deployers, and users of AI systems.\n",
            "5. **Social Impact**: AI has the potential to exacerbate existing social inequalities and disparities, particularly in areas such as healthcare, education, and employment.\n",
            "6. **Autonomous Weapons**: The use of AI in autonomous weapons systems raises significant ethical and security concerns, and international discussions and regulations are needed to address the risks associated with AI-powered weapons.\n",
            "\n",
            "These concerns highlight the need for a comprehensive approach to ensuring that AI systems are developed and deployed in a way that is fair, transparent, accountable, and beneficial to society.\n",
            "\n",
            "=== EVALUATION RESULTS ===\n",
            "Based on the evaluation criteria, here is the ranking of the responses:\n",
            "\n",
            "1. **Reference Answer**: This response is the most accurate, comprehensive, and relevant to the query. It covers a wide range of ethical concerns surrounding the use of AI in decision-making, including bias, transparency, explainability, privacy, job displacement, accountability, and social impact. The reference answer also highlights the importance of ensuring fairness, accountability, and transparency in AI systems.\n",
            "\n",
            "2. **Standard Response**: This response is comprehensive and covers most of the key ethical concerns surrounding AI in decision-making. It includes bias and fairness, transparency and explainability, robustness and reliability, user control and agency, ethical design and development, addressing bias in AI, transparency and explainability, privacy and data security, accountability, and social impact. However, it lacks some specific details and examples, making it slightly less detailed than the reference answer.\n",
            "\n",
            "3. **Selective Response**: This response is concise and covers some of the key ethical concerns surrounding AI in decision-making, including bias and fairness, transparency and explainability, privacy and data security, job displacement, accountability, and autonomy and control issues. However, it omits some important concerns, such as respect for human rights, non-discrimination, and public perception and trust. This response also lacks specific details and examples.\n",
            "\n",
            "4. **Summary Response**: This response is concise but lacks the depth and breadth of the reference and standard responses. It covers some of the key ethical concerns, including bias and fairness, transparency and explainability, privacy and data security, job displacement, autonomy and control issues, accountability, and social impact. However, it does not provide specific details or examples, and some concerns are not mentioned at all.\n",
            "\n",
            "5. **Extraction Response**: This response is the least comprehensive and most superficial of the four. It only covers a few key concerns, including bias and fairness, lack of transparency and explainability, privacy and data protection, accountability, social impact, and autonomous weapons. The response lacks specific details, examples, and other important concerns, making it the least accurate and relevant to the query.\n",
            "\n",
            "Overall, the reference answer is the most accurate, comprehensive, and relevant to the query, followed by the standard response. The selective and summary responses are less comprehensive, while the extraction response is the least comprehensive and most superficial.\n"
          ]
        }
      ],
      "source": [
        "# Path to the PDF document containing information on AI ethics\n",
        "pdf_path = \"AI_Information.pdf\"\n",
        "\n",
        "# Query to extract relevant information from the document\n",
        "query = \"What are the ethical concerns surrounding the use of AI in decision-making?\"\n",
        "\n",
        "# Optional reference answer for evaluation\n",
        "reference_answer = \"\"\"\n",
        "The use of AI in decision-making raises several ethical concerns.\n",
        "- Bias in AI models can lead to unfair or discriminatory outcomes, especially in critical areas like hiring, lending, and law enforcement.\n",
        "- Lack of transparency and explainability in AI-driven decisions makes it difficult for individuals to challenge unfair outcomes.\n",
        "- Privacy risks arise as AI systems process vast amounts of personal data, often without explicit consent.\n",
        "- The potential for job displacement due to automation raises social and economic concerns.\n",
        "- AI decision-making may also concentrate power in the hands of a few large tech companies, leading to accountability challenges.\n",
        "- Ensuring fairness, accountability, and transparency in AI systems is essential for ethical deployment.\n",
        "\"\"\"\n",
        "\n",
        "# Run evaluation with different compression techniques\n",
        "# Compression types:\n",
        "# - \"selective\": Retains key details while omitting less relevant parts\n",
        "# - \"summary\": Provides a concise version of the information\n",
        "# - \"extraction\": Extracts relevant sentences verbatim from the document\n",
        "results = evaluate_compression(\n",
        "    pdf_path=pdf_path,\n",
        "    query=query,\n",
        "    reference_answer=reference_answer,\n",
        "    compression_types=[\"selective\", \"summary\", \"extraction\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwPJ5bQ8Gd0k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
